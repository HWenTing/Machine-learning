{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def load_mnist_train(path):\n",
    "    labels_path = os.path.join(path,'train-labels.idx1-ubyte')\n",
    "    images_path = os.path.join(path, 'train-images.idx3-ubyte')\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II',lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath, dtype=np.uint8)\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII',imgpath.read(16))\n",
    "        images = np.fromfile(imgpath, dtype=np.uint8).reshape(len(labels), 784)\n",
    "    return images, labels\n",
    "def load_mnist_test(path):\n",
    "    labels_path = os.path.join(path,'t10k-labels.idx1-ubyte')\n",
    "    images_path = os.path.join(path, 't10k-images.idx3-ubyte')\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II',lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath, dtype=np.uint8)\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII',imgpath.read(16))\n",
    "        images = np.fromfile(imgpath, dtype=np.uint8).reshape(len(labels), 784)\n",
    "    return images, labels\n",
    "X_train,Y_train = load_mnist_train('E:\\学习\\大三\\机器学习\\MNIST')\n",
    "X_test,Y_test = load_mnist_test('E:\\学习\\大三\\机器学习\\MNIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path = 'D:\\LIBSVM\\libsvm-3.22\\python'\n",
    "sys.path.append(path)\n",
    "from svmutil import *\n",
    "from svm  import *\n",
    "\n",
    "y_train_svm = Y_train.tolist()\n",
    "x_train_svm=[]\n",
    "index = range(1,785)\n",
    "for i in X_train:\n",
    "    x_train_svm.append(dict(zip(index, i)))\n",
    "    \n",
    "y_test_svm = Y_test.tolist()\n",
    "x_test_svm=[]\n",
    "index = range(1,785)\n",
    "for i in X_test:\n",
    "    x_test_svm.append(dict(zip(index, i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_svm(nums,typet):\n",
    "    start =time.clock()\n",
    "    prob  = svm_problem(y_train_svm[:nums], x_train_svm[:nums])\n",
    "    param = svm_parameter('-t %d -c 4 -m 1024'%typet)\n",
    "    model = svm_train(prob, param)\n",
    "    end1 = time.clock()\n",
    "    print('training time: %s Seconds'%(end1-start))\n",
    "    p_label, p_acc, p_val = svm_predict(y_test_svm[:1000], x_test_svm[:1000], model)\n",
    "    end = time.clock()\n",
    "    print('Running time: %s Seconds'%(end-start))\n",
    "    return p_acc[0],end1-start,end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_time(types):\n",
    "    ac=[]\n",
    "    train_time=[]\n",
    "    total_time=[]\n",
    "    for i in range(100):\n",
    "        a,b,c = test_svm((i+1)*100,types)\n",
    "        ac.append(a)\n",
    "        train_time.append(b)\n",
    "        total_time.append(c)\n",
    "    return ac,train_time,total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 0.299554410404653 Seconds\n",
      "Accuracy = 62.2% (622/1000) (classification)\n",
      "Running time: 1.5506304585123871 Seconds\n",
      "training time: 0.5315588761773142 Seconds\n",
      "Accuracy = 73.7% (737/1000) (classification)\n",
      "Running time: 1.8328507660039577 Seconds\n",
      "training time: 0.6470510849762832 Seconds\n",
      "Accuracy = 80.6% (806/1000) (classification)\n",
      "Running time: 1.9988618285092343 Seconds\n",
      "training time: 0.8055642798253757 Seconds\n",
      "Accuracy = 83% (830/1000) (classification)\n",
      "Running time: 2.1993641093959013 Seconds\n",
      "training time: 1.0296074710822722 Seconds\n",
      "Accuracy = 84.1% (841/1000) (classification)\n",
      "Running time: 2.485522782590124 Seconds\n",
      "training time: 1.120800251891069 Seconds\n",
      "Accuracy = 86% (860/1000) (classification)\n",
      "Running time: 2.6343115445197327 Seconds\n",
      "training time: 1.3513082256099551 Seconds\n",
      "Accuracy = 84.9% (849/1000) (classification)\n",
      "Running time: 2.917802764085536 Seconds\n",
      "training time: 1.492817588759408 Seconds\n",
      "Accuracy = 84.1% (841/1000) (classification)\n",
      "Running time: 3.1615152653644145 Seconds\n",
      "training time: 1.948388406848153 Seconds\n",
      "Accuracy = 84.4% (844/1000) (classification)\n",
      "Running time: 3.7978360914535187 Seconds\n",
      "training time: 1.7857890933855742 Seconds\n",
      "Accuracy = 84.8% (848/1000) (classification)\n",
      "Running time: 3.4510813419283295 Seconds\n",
      "training time: 2.202452698327761 Seconds\n",
      "Accuracy = 85.1% (851/1000) (classification)\n",
      "Running time: 3.9653385102160428 Seconds\n",
      "training time: 2.2460026714043124 Seconds\n",
      "Accuracy = 85.1% (851/1000) (classification)\n",
      "Running time: 4.000690172021223 Seconds\n",
      "training time: 2.368976550348634 Seconds\n",
      "Accuracy = 85.1% (851/1000) (classification)\n",
      "Running time: 4.17172641375646 Seconds\n",
      "training time: 2.670690760663092 Seconds\n",
      "Accuracy = 86.2% (862/1000) (classification)\n",
      "Running time: 4.652538090819235 Seconds\n",
      "training time: 2.705257435743988 Seconds\n",
      "Accuracy = 85.6% (856/1000) (classification)\n",
      "Running time: 4.601754546068605 Seconds\n",
      "training time: 2.9219177221712016 Seconds\n",
      "Accuracy = 86.2% (862/1000) (classification)\n",
      "Running time: 4.914957927951036 Seconds\n",
      "training time: 3.2649182045415728 Seconds\n",
      "Accuracy = 86.7% (867/1000) (classification)\n",
      "Running time: 5.248047508487161 Seconds\n",
      "training time: 3.5043600935978247 Seconds\n",
      "Accuracy = 86.5% (865/1000) (classification)\n",
      "Running time: 5.5863898235379565 Seconds\n",
      "training time: 3.419109034142366 Seconds\n",
      "Accuracy = 86.6% (866/1000) (classification)\n",
      "Running time: 5.568945103472743 Seconds\n",
      "training time: 3.684443238190397 Seconds\n",
      "Accuracy = 87.1% (871/1000) (classification)\n",
      "Running time: 5.841907940454803 Seconds\n",
      "training time: 3.6720643886642392 Seconds\n",
      "Accuracy = 88.1% (881/1000) (classification)\n",
      "Running time: 5.739303025023673 Seconds\n",
      "training time: 3.9464340387939956 Seconds\n",
      "Accuracy = 88.3% (883/1000) (classification)\n",
      "Running time: 6.160682871289282 Seconds\n",
      "training time: 4.7372988792508295 Seconds\n",
      "Accuracy = 87.9% (879/1000) (classification)\n",
      "Running time: 6.932615190974502 Seconds\n",
      "training time: 4.246790423557286 Seconds\n",
      "Accuracy = 87.9% (879/1000) (classification)\n",
      "Running time: 6.351964817424687 Seconds\n",
      "training time: 4.469574159516924 Seconds\n",
      "Accuracy = 87.3% (873/1000) (classification)\n",
      "Running time: 6.618266921560007 Seconds\n",
      "training time: 4.679621515510007 Seconds\n",
      "Accuracy = 87.6% (876/1000) (classification)\n",
      "Running time: 6.865569739571583 Seconds\n",
      "training time: 5.037798671251039 Seconds\n",
      "Accuracy = 87.9% (879/1000) (classification)\n",
      "Running time: 7.465029374779988 Seconds\n",
      "training time: 5.664533335861506 Seconds\n",
      "Accuracy = 87.7% (877/1000) (classification)\n",
      "Running time: 7.942780512260015 Seconds\n",
      "training time: 5.401956659409279 Seconds\n",
      "Accuracy = 88% (880/1000) (classification)\n",
      "Running time: 7.6568604560666245 Seconds\n",
      "training time: 5.849114252901927 Seconds\n",
      "Accuracy = 87.5% (875/1000) (classification)\n",
      "Running time: 8.219726356867795 Seconds\n",
      "training time: 5.776630388191279 Seconds\n",
      "Accuracy = 87.5% (875/1000) (classification)\n",
      "Running time: 8.071440902983795 Seconds\n",
      "training time: 6.140697907320828 Seconds\n",
      "Accuracy = 86.7% (867/1000) (classification)\n",
      "Running time: 8.47496398028943 Seconds\n",
      "training time: 6.295175156335517 Seconds\n",
      "Accuracy = 87.3% (873/1000) (classification)\n",
      "Running time: 8.662906473592557 Seconds\n",
      "training time: 6.535330526027792 Seconds\n",
      "Accuracy = 87.5% (875/1000) (classification)\n",
      "Running time: 8.920090168781826 Seconds\n",
      "training time: 6.825932848277262 Seconds\n",
      "Accuracy = 88.1% (881/1000) (classification)\n",
      "Running time: 9.30541869975059 Seconds\n",
      "training time: 7.154391125659913 Seconds\n",
      "Accuracy = 88.6% (886/1000) (classification)\n",
      "Running time: 9.555937316420113 Seconds\n",
      "training time: 7.404535224254687 Seconds\n",
      "Accuracy = 88% (880/1000) (classification)\n",
      "Running time: 9.84012463392628 Seconds\n",
      "training time: 7.408439614689087 Seconds\n",
      "Accuracy = 88.5% (885/1000) (classification)\n",
      "Running time: 10.25401135327047 Seconds\n",
      "training time: 7.838960388392934 Seconds\n",
      "Accuracy = 88.6% (886/1000) (classification)\n",
      "Running time: 10.455513534206148 Seconds\n",
      "training time: 7.838009080878237 Seconds\n",
      "Accuracy = 89.6% (896/1000) (classification)\n",
      "Running time: 10.430993662032051 Seconds\n",
      "training time: 8.454573288407119 Seconds\n",
      "Accuracy = 89.7% (897/1000) (classification)\n",
      "Running time: 11.47249208198491 Seconds\n",
      "training time: 8.40281038679268 Seconds\n",
      "Accuracy = 89.4% (894/1000) (classification)\n",
      "Running time: 11.135931098155652 Seconds\n",
      "training time: 8.648371774769203 Seconds\n",
      "Accuracy = 89.3% (893/1000) (classification)\n",
      "Running time: 11.268463879351657 Seconds\n",
      "training time: 9.113526779030053 Seconds\n",
      "Accuracy = 89.7% (897/1000) (classification)\n",
      "Running time: 11.75674576978281 Seconds\n",
      "training time: 8.909696502088082 Seconds\n",
      "Accuracy = 89.4% (894/1000) (classification)\n",
      "Running time: 11.809317756858036 Seconds\n",
      "training time: 9.250300147792586 Seconds\n",
      "Accuracy = 89.5% (895/1000) (classification)\n",
      "Running time: 11.986552114703954 Seconds\n",
      "training time: 10.19012244133637 Seconds\n",
      "Accuracy = 89.5% (895/1000) (classification)\n",
      "Running time: 12.95174761274393 Seconds\n",
      "training time: 10.695118978624578 Seconds\n",
      "Accuracy = 89.1% (891/1000) (classification)\n",
      "Running time: 13.595659145885747 Seconds\n",
      "training time: 11.069759917321335 Seconds\n",
      "Accuracy = 88.8% (888/1000) (classification)\n",
      "Running time: 13.856870095561135 Seconds\n",
      "training time: 10.244723858105317 Seconds\n",
      "Accuracy = 88.8% (888/1000) (classification)\n",
      "Running time: 13.014650451772468 Seconds\n",
      "training time: 10.709785232847025 Seconds\n",
      "Accuracy = 88.1% (881/1000) (classification)\n",
      "Running time: 13.660240600208908 Seconds\n",
      "training time: 11.257132337225812 Seconds\n",
      "Accuracy = 88.2% (882/1000) (classification)\n",
      "Running time: 14.20830158028457 Seconds\n",
      "training time: 11.88150848611349 Seconds\n",
      "Accuracy = 88.5% (885/1000) (classification)\n",
      "Running time: 14.835785676105843 Seconds\n",
      "training time: 12.338663894916863 Seconds\n",
      "Accuracy = 88.8% (888/1000) (classification)\n",
      "Running time: 15.395253655007764 Seconds\n",
      "training time: 12.185625459012044 Seconds\n",
      "Accuracy = 89% (890/1000) (classification)\n",
      "Running time: 15.191076514279757 Seconds\n",
      "training time: 12.28433625560183 Seconds\n",
      "Accuracy = 89.1% (891/1000) (classification)\n",
      "Running time: 15.389767439288335 Seconds\n",
      "training time: 12.27293952836817 Seconds\n",
      "Accuracy = 89.5% (895/1000) (classification)\n",
      "Running time: 15.276013500033514 Seconds\n",
      "training time: 12.562404469249032 Seconds\n",
      "Accuracy = 89.6% (896/1000) (classification)\n",
      "Running time: 15.530797593128682 Seconds\n",
      "training time: 13.332856099331366 Seconds\n",
      "Accuracy = 89.4% (894/1000) (classification)\n",
      "Running time: 16.683983781945244 Seconds\n",
      "training time: 13.337036637586607 Seconds\n",
      "Accuracy = 88.9% (889/1000) (classification)\n",
      "Running time: 16.43543296541293 Seconds\n",
      "training time: 13.100614991863495 Seconds\n",
      "Accuracy = 89.2% (892/1000) (classification)\n",
      "Running time: 16.17445075620617 Seconds\n",
      "training time: 13.41168583306353 Seconds\n",
      "Accuracy = 88.7% (887/1000) (classification)\n",
      "Running time: 16.44359295574168 Seconds\n",
      "training time: 14.470966750458956 Seconds\n",
      "Accuracy = 88.4% (884/1000) (classification)\n",
      "Running time: 17.698800159446364 Seconds\n",
      "training time: 14.887983145106318 Seconds\n",
      "Accuracy = 88.5% (885/1000) (classification)\n",
      "Running time: 17.956628594612994 Seconds\n",
      "training time: 14.73746006424517 Seconds\n",
      "Accuracy = 88.8% (888/1000) (classification)\n",
      "Running time: 17.971832527211063 Seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 14.67495031117005 Seconds\n",
      "Accuracy = 89.3% (893/1000) (classification)\n",
      "Running time: 17.759849371042947 Seconds\n",
      "training time: 14.872358867327875 Seconds\n",
      "Accuracy = 89.2% (892/1000) (classification)\n",
      "Running time: 17.932739635271446 Seconds\n",
      "training time: 15.077221044281032 Seconds\n",
      "Accuracy = 89.8% (898/1000) (classification)\n",
      "Running time: 18.70339116635114 Seconds\n",
      "training time: 15.710041232543972 Seconds\n",
      "Accuracy = 89.5% (895/1000) (classification)\n",
      "Running time: 18.878325082479023 Seconds\n",
      "training time: 15.557423536880378 Seconds\n",
      "Accuracy = 89.5% (895/1000) (classification)\n",
      "Running time: 18.839220733762886 Seconds\n",
      "training time: 16.808139289119026 Seconds\n",
      "Accuracy = 88.6% (886/1000) (classification)\n",
      "Running time: 20.44411601685033 Seconds\n",
      "training time: 17.636122900397368 Seconds\n",
      "Accuracy = 88.8% (888/1000) (classification)\n",
      "Running time: 21.123846174206847 Seconds\n",
      "training time: 21.731935527582664 Seconds\n",
      "Accuracy = 89.6% (896/1000) (classification)\n",
      "Running time: 27.319869645587005 Seconds\n",
      "training time: 19.88680349218339 Seconds\n",
      "Accuracy = 89.9% (899/1000) (classification)\n",
      "Running time: 23.940250144888978 Seconds\n",
      "training time: 18.587312291580474 Seconds\n",
      "Accuracy = 89.3% (893/1000) (classification)\n",
      "Running time: 21.90902529300729 Seconds\n",
      "training time: 18.237814631725996 Seconds\n",
      "Accuracy = 89.6% (896/1000) (classification)\n",
      "Running time: 21.68606852021503 Seconds\n",
      "training time: 19.095936676420934 Seconds\n",
      "Accuracy = 89.9% (899/1000) (classification)\n",
      "Running time: 22.40416900246646 Seconds\n",
      "training time: 18.67372957187581 Seconds\n",
      "Accuracy = 90.2% (902/1000) (classification)\n",
      "Running time: 22.03156934530034 Seconds\n",
      "training time: 18.698732603971166 Seconds\n",
      "Accuracy = 90% (900/1000) (classification)\n",
      "Running time: 22.024230292270204 Seconds\n",
      "training time: 19.569864015963503 Seconds\n",
      "Accuracy = 89.9% (899/1000) (classification)\n",
      "Running time: 23.178412035462316 Seconds\n",
      "training time: 20.12000538863549 Seconds\n",
      "Accuracy = 90.1% (901/1000) (classification)\n",
      "Running time: 23.930543094665154 Seconds\n",
      "training time: 19.73120861486359 Seconds\n",
      "Accuracy = 89.7% (897/1000) (classification)\n",
      "Running time: 23.12927826653413 Seconds\n",
      "training time: 20.457949086875033 Seconds\n",
      "Accuracy = 89.8% (898/1000) (classification)\n",
      "Running time: 23.863141298005303 Seconds\n",
      "training time: 21.04964971893378 Seconds\n",
      "Accuracy = 89.9% (899/1000) (classification)\n",
      "Running time: 24.531368061588637 Seconds\n",
      "training time: 21.33297817326047 Seconds\n",
      "Accuracy = 89.7% (897/1000) (classification)\n",
      "Running time: 25.18604224864157 Seconds\n",
      "training time: 21.97945799965464 Seconds\n",
      "Accuracy = 90.2% (902/1000) (classification)\n",
      "Running time: 25.638541070371048 Seconds\n",
      "training time: 21.640536919857823 Seconds\n",
      "Accuracy = 90.1% (901/1000) (classification)\n",
      "Running time: 25.229726937607666 Seconds\n",
      "training time: 22.14149435082163 Seconds\n",
      "Accuracy = 90.4% (904/1000) (classification)\n",
      "Running time: 25.730753504292352 Seconds\n",
      "training time: 23.32616731713506 Seconds\n",
      "Accuracy = 90.6% (906/1000) (classification)\n",
      "Running time: 27.064987972360086 Seconds\n",
      "training time: 23.13111135078134 Seconds\n",
      "Accuracy = 90.2% (902/1000) (classification)\n",
      "Running time: 26.968246951213587 Seconds\n",
      "training time: 22.9189543676589 Seconds\n",
      "Accuracy = 90.2% (902/1000) (classification)\n",
      "Running time: 26.528929743490608 Seconds\n",
      "training time: 23.35195849644424 Seconds\n",
      "Accuracy = 90.3% (903/1000) (classification)\n",
      "Running time: 27.021463678265263 Seconds\n",
      "training time: 23.707506519498565 Seconds\n",
      "Accuracy = 89.9% (899/1000) (classification)\n",
      "Running time: 27.404328607215575 Seconds\n",
      "training time: 24.517891336820412 Seconds\n",
      "Accuracy = 89.8% (898/1000) (classification)\n",
      "Running time: 28.465318559622574 Seconds\n",
      "training time: 25.09640758944306 Seconds\n",
      "Accuracy = 90% (900/1000) (classification)\n",
      "Running time: 28.94034614477505 Seconds\n",
      "training time: 25.68902673893126 Seconds\n",
      "Accuracy = 89.8% (898/1000) (classification)\n",
      "Running time: 29.467298211597154 Seconds\n",
      "training time: 25.310729113210073 Seconds\n",
      "Accuracy = 90.1% (901/1000) (classification)\n",
      "Running time: 29.10318407523846 Seconds\n",
      "training time: 25.891563980368574 Seconds\n",
      "Accuracy = 90% (900/1000) (classification)\n",
      "Running time: 29.690285799167214 Seconds\n",
      "training time: 26.276613598087806 Seconds\n",
      "Accuracy = 90.2% (902/1000) (classification)\n",
      "Running time: 30.351345756429964 Seconds\n",
      "training time: 26.316669649379037 Seconds\n",
      "Accuracy = 90.1% (901/1000) (classification)\n",
      "Running time: 30.12892982250287 Seconds\n"
     ]
    }
   ],
   "source": [
    "# 线性核\n",
    "ac,train_time,total_time = check_time(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 0.15668801182619063 Seconds\n",
      "Accuracy = 52.1% (521/1000) (classification)\n",
      "Running time: 1.446813890195699 Seconds\n",
      "training time: 0.3037100598003235 Seconds\n",
      "Accuracy = 64.7% (647/1000) (classification)\n",
      "Running time: 1.6165369483019276 Seconds\n",
      "training time: 0.4658313491381705 Seconds\n",
      "Accuracy = 72% (720/1000) (classification)\n",
      "Running time: 1.8355277011028193 Seconds\n",
      "training time: 0.6256348140627779 Seconds\n",
      "Accuracy = 75.7% (757/1000) (classification)\n",
      "Running time: 2.1872645681805807 Seconds\n",
      "training time: 0.7968389568327439 Seconds\n",
      "Accuracy = 78.2% (782/1000) (classification)\n",
      "Running time: 2.249871506325235 Seconds\n",
      "training time: 0.957917284443738 Seconds\n",
      "Accuracy = 82.5% (825/1000) (classification)\n",
      "Running time: 2.4840788336846344 Seconds\n",
      "training time: 1.1972130008339263 Seconds\n",
      "Accuracy = 83.5% (835/1000) (classification)\n",
      "Running time: 2.7877884984236516 Seconds\n",
      "training time: 1.3139950846480133 Seconds\n",
      "Accuracy = 84.5% (845/1000) (classification)\n",
      "Running time: 2.9888900872415434 Seconds\n",
      "training time: 1.5237963174758988 Seconds\n",
      "Accuracy = 85.1% (851/1000) (classification)\n",
      "Running time: 3.144877655453911 Seconds\n",
      "training time: 1.697268902002179 Seconds\n",
      "Accuracy = 85.4% (854/1000) (classification)\n",
      "Running time: 3.3982189848270536 Seconds\n",
      "training time: 2.0137208726273457 Seconds\n",
      "Accuracy = 86.2% (862/1000) (classification)\n",
      "Running time: 3.845655096507926 Seconds\n",
      "training time: 2.135458209826993 Seconds\n",
      "Accuracy = 86.2% (862/1000) (classification)\n",
      "Running time: 3.8495519807775054 Seconds\n",
      "training time: 2.315702934475212 Seconds\n",
      "Accuracy = 86.7% (867/1000) (classification)\n",
      "Running time: 4.054175145668978 Seconds\n",
      "training time: 2.5214532091417823 Seconds\n",
      "Accuracy = 86.4% (864/1000) (classification)\n",
      "Running time: 4.287517683929309 Seconds\n",
      "training time: 2.78360479967796 Seconds\n",
      "Accuracy = 87.2% (872/1000) (classification)\n",
      "Running time: 4.562578296203355 Seconds\n",
      "training time: 2.9438957701972868 Seconds\n",
      "Accuracy = 87.6% (876/1000) (classification)\n",
      "Running time: 4.801516087091841 Seconds\n",
      "training time: 3.2278077300056793 Seconds\n",
      "Accuracy = 87.6% (876/1000) (classification)\n",
      "Running time: 5.111412411165929 Seconds\n",
      "training time: 3.576549637669359 Seconds\n",
      "Accuracy = 88.9% (889/1000) (classification)\n",
      "Running time: 5.772268911878655 Seconds\n",
      "training time: 3.8503270909700404 Seconds\n",
      "Accuracy = 88.6% (886/1000) (classification)\n",
      "Running time: 5.929410454031768 Seconds\n",
      "training time: 4.197852209952998 Seconds\n",
      "Accuracy = 88.6% (886/1000) (classification)\n",
      "Running time: 6.2679179046895115 Seconds\n",
      "training time: 4.365974874894164 Seconds\n",
      "Accuracy = 89.1% (891/1000) (classification)\n",
      "Running time: 6.443605597702117 Seconds\n",
      "training time: 4.361389398846768 Seconds\n",
      "Accuracy = 89.6% (896/1000) (classification)\n",
      "Running time: 6.356788120349847 Seconds\n",
      "training time: 4.8002680885711015 Seconds\n",
      "Accuracy = 89.8% (898/1000) (classification)\n",
      "Running time: 7.048564485652605 Seconds\n",
      "training time: 4.945355126492359 Seconds\n",
      "Accuracy = 90.1% (901/1000) (classification)\n",
      "Running time: 7.1982496415803325 Seconds\n",
      "training time: 5.234953203018449 Seconds\n",
      "Accuracy = 90.2% (902/1000) (classification)\n",
      "Running time: 7.357516613313237 Seconds\n",
      "training time: 5.394224125364417 Seconds\n",
      "Accuracy = 90.2% (902/1000) (classification)\n",
      "Running time: 7.788254275649706 Seconds\n",
      "training time: 5.61132253472897 Seconds\n",
      "Accuracy = 90.2% (902/1000) (classification)\n",
      "Running time: 7.797278660015763 Seconds\n",
      "training time: 5.828430820624817 Seconds\n",
      "Accuracy = 90.5% (905/1000) (classification)\n",
      "Running time: 8.231560416916182 Seconds\n",
      "training time: 5.985150437352786 Seconds\n",
      "Accuracy = 90.6% (906/1000) (classification)\n",
      "Running time: 8.140029068607873 Seconds\n",
      "training time: 6.327608105550098 Seconds\n",
      "Accuracy = 90.6% (906/1000) (classification)\n",
      "Running time: 8.504751599306474 Seconds\n",
      "training time: 6.629202612302834 Seconds\n",
      "Accuracy = 91% (910/1000) (classification)\n",
      "Running time: 8.825221738008622 Seconds\n",
      "training time: 6.746837238316402 Seconds\n",
      "Accuracy = 91.4% (914/1000) (classification)\n",
      "Running time: 8.975283782379847 Seconds\n",
      "training time: 6.989554975341889 Seconds\n",
      "Accuracy = 91.9% (919/1000) (classification)\n",
      "Running time: 9.294801428382925 Seconds\n",
      "training time: 7.263192576957408 Seconds\n",
      "Accuracy = 91.9% (919/1000) (classification)\n",
      "Running time: 9.712850513164994 Seconds\n",
      "training time: 7.62498651853457 Seconds\n",
      "Accuracy = 92% (920/1000) (classification)\n",
      "Running time: 9.948835221132867 Seconds\n",
      "training time: 7.969022456466519 Seconds\n",
      "Accuracy = 92.2% (922/1000) (classification)\n",
      "Running time: 10.48959744442709 Seconds\n",
      "training time: 8.659381341967674 Seconds\n",
      "Accuracy = 92.3% (923/1000) (classification)\n",
      "Running time: 11.300343742802397 Seconds\n",
      "training time: 8.750964838362961 Seconds\n",
      "Accuracy = 92.2% (922/1000) (classification)\n",
      "Running time: 11.173525917796724 Seconds\n",
      "training time: 8.988766828128973 Seconds\n",
      "Accuracy = 92% (920/1000) (classification)\n",
      "Running time: 11.46466433817568 Seconds\n",
      "training time: 9.51963079154848 Seconds\n",
      "Accuracy = 91.9% (919/1000) (classification)\n",
      "Running time: 12.163948842727223 Seconds\n",
      "training time: 9.471246848892406 Seconds\n",
      "Accuracy = 92% (920/1000) (classification)\n",
      "Running time: 11.952613982086405 Seconds\n",
      "training time: 9.835712984834572 Seconds\n",
      "Accuracy = 92.1% (921/1000) (classification)\n",
      "Running time: 12.494508846014469 Seconds\n",
      "training time: 10.0748024792465 Seconds\n",
      "Accuracy = 92.2% (922/1000) (classification)\n",
      "Running time: 12.58765520475481 Seconds\n",
      "training time: 10.346413021535227 Seconds\n",
      "Accuracy = 92.1% (921/1000) (classification)\n",
      "Running time: 13.060378397576642 Seconds\n",
      "training time: 10.363650334439626 Seconds\n",
      "Accuracy = 92.2% (922/1000) (classification)\n",
      "Running time: 12.911457685186178 Seconds\n",
      "training time: 10.46404606730357 Seconds\n",
      "Accuracy = 92.3% (923/1000) (classification)\n",
      "Running time: 13.040696840655983 Seconds\n",
      "training time: 10.794756193869034 Seconds\n",
      "Accuracy = 92.7% (927/1000) (classification)\n",
      "Running time: 13.476343534210173 Seconds\n",
      "training time: 11.344247690768498 Seconds\n",
      "Accuracy = 92.7% (927/1000) (classification)\n",
      "Running time: 14.325121985040823 Seconds\n",
      "training time: 12.18659651958933 Seconds\n",
      "Accuracy = 92.8% (928/1000) (classification)\n",
      "Running time: 14.955798175844393 Seconds\n",
      "training time: 12.456668693331267 Seconds\n",
      "Accuracy = 92.8% (928/1000) (classification)\n",
      "Running time: 15.392485065696746 Seconds\n",
      "training time: 12.067548759448073 Seconds\n",
      "Accuracy = 93.1% (931/1000) (classification)\n",
      "Running time: 14.763206601631282 Seconds\n",
      "training time: 12.443999868839455 Seconds\n",
      "Accuracy = 92.9% (929/1000) (classification)\n",
      "Running time: 15.1840132140087 Seconds\n",
      "training time: 12.499634765865267 Seconds\n",
      "Accuracy = 92.8% (928/1000) (classification)\n",
      "Running time: 15.185331928495543 Seconds\n",
      "training time: 14.380582660050095 Seconds\n",
      "Accuracy = 92.9% (929/1000) (classification)\n",
      "Running time: 17.453725486942858 Seconds\n",
      "training time: 14.65301453469965 Seconds\n",
      "Accuracy = 92.5% (925/1000) (classification)\n",
      "Running time: 17.98876880343505 Seconds\n",
      "training time: 14.668488294137205 Seconds\n",
      "Accuracy = 92.7% (927/1000) (classification)\n",
      "Running time: 17.693598782894696 Seconds\n",
      "training time: 15.251474269857681 Seconds\n",
      "Accuracy = 92.7% (927/1000) (classification)\n",
      "Running time: 18.171470414059513 Seconds\n",
      "training time: 15.10543118368696 Seconds\n",
      "Accuracy = 92.6% (926/1000) (classification)\n",
      "Running time: 17.850324720602657 Seconds\n",
      "training time: 14.481607330440966 Seconds\n",
      "Accuracy = 92.5% (925/1000) (classification)\n",
      "Running time: 17.296372587014957 Seconds\n",
      "training time: 14.89992189638906 Seconds\n",
      "Accuracy = 92.7% (927/1000) (classification)\n",
      "Running time: 17.735713103352282 Seconds\n",
      "training time: 15.54756596831703 Seconds\n",
      "Accuracy = 92.7% (927/1000) (classification)\n",
      "Running time: 18.6354599876031 Seconds\n",
      "training time: 15.364167074567376 Seconds\n",
      "Accuracy = 92.9% (929/1000) (classification)\n",
      "Running time: 18.38268320077077 Seconds\n",
      "training time: 16.67580838422782 Seconds\n",
      "Accuracy = 92.9% (929/1000) (classification)\n",
      "Running time: 20.792028295867567 Seconds\n",
      "training time: 17.67581707557474 Seconds\n",
      "Accuracy = 93% (930/1000) (classification)\n",
      "Running time: 20.60050378211963 Seconds\n",
      "training time: 16.645627284195143 Seconds\n",
      "Accuracy = 93.3% (933/1000) (classification)\n",
      "Running time: 19.539796693574317 Seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 16.990123468495767 Seconds\n",
      "Accuracy = 93.4% (934/1000) (classification)\n",
      "Running time: 20.200918675454886 Seconds\n",
      "training time: 16.96357140119926 Seconds\n",
      "Accuracy = 93.3% (933/1000) (classification)\n",
      "Running time: 19.942422586757857 Seconds\n",
      "training time: 17.728946494088632 Seconds\n",
      "Accuracy = 93.7% (937/1000) (classification)\n",
      "Running time: 20.827568006832735 Seconds\n",
      "training time: 18.11248223705752 Seconds\n",
      "Accuracy = 93.7% (937/1000) (classification)\n",
      "Running time: 21.28115956800866 Seconds\n",
      "training time: 18.690735773942833 Seconds\n",
      "Accuracy = 93.6% (936/1000) (classification)\n",
      "Running time: 22.03590000683471 Seconds\n",
      "training time: 18.457107211330367 Seconds\n",
      "Accuracy = 93.7% (937/1000) (classification)\n",
      "Running time: 21.465748781334696 Seconds\n",
      "training time: 18.93964846658946 Seconds\n",
      "Accuracy = 93.8% (938/1000) (classification)\n",
      "Running time: 21.956455162719976 Seconds\n",
      "training time: 19.35926515445135 Seconds\n",
      "Accuracy = 93.7% (937/1000) (classification)\n",
      "Running time: 22.439425454507727 Seconds\n",
      "training time: 19.235604659036653 Seconds\n",
      "Accuracy = 93.8% (938/1000) (classification)\n",
      "Running time: 22.319992904699575 Seconds\n",
      "training time: 20.27659621539169 Seconds\n",
      "Accuracy = 93.8% (938/1000) (classification)\n",
      "Running time: 23.667154962384302 Seconds\n",
      "training time: 21.821715964386385 Seconds\n",
      "Accuracy = 93.7% (937/1000) (classification)\n",
      "Running time: 24.948030876407756 Seconds\n",
      "training time: 20.561016619041766 Seconds\n",
      "Accuracy = 93.8% (938/1000) (classification)\n",
      "Running time: 23.701236897299168 Seconds\n",
      "training time: 20.738271520072885 Seconds\n",
      "Accuracy = 94% (940/1000) (classification)\n",
      "Running time: 23.990310727532233 Seconds\n",
      "training time: 21.33429175195033 Seconds\n",
      "Accuracy = 94% (940/1000) (classification)\n",
      "Running time: 24.523575083169817 Seconds\n",
      "training time: 21.61682692326667 Seconds\n",
      "Accuracy = 94% (940/1000) (classification)\n",
      "Running time: 24.835008985668537 Seconds\n",
      "training time: 21.921187648962587 Seconds\n",
      "Accuracy = 94.1% (941/1000) (classification)\n",
      "Running time: 25.173825374231455 Seconds\n",
      "training time: 22.29706987013924 Seconds\n",
      "Accuracy = 94.2% (942/1000) (classification)\n",
      "Running time: 25.549155694828187 Seconds\n",
      "training time: 22.546099105858048 Seconds\n",
      "Accuracy = 93.9% (939/1000) (classification)\n",
      "Running time: 25.956595014406048 Seconds\n",
      "training time: 23.024359872363675 Seconds\n",
      "Accuracy = 93.9% (939/1000) (classification)\n",
      "Running time: 26.33392276473387 Seconds\n",
      "training time: 23.673599596721942 Seconds\n",
      "Accuracy = 94.1% (941/1000) (classification)\n",
      "Running time: 26.97338314265744 Seconds\n",
      "training time: 24.93390941166308 Seconds\n",
      "Accuracy = 93.7% (937/1000) (classification)\n",
      "Running time: 28.247503904192854 Seconds\n",
      "training time: 24.342665075359946 Seconds\n",
      "Accuracy = 93.7% (937/1000) (classification)\n",
      "Running time: 27.678009665568425 Seconds\n",
      "training time: 24.625202617044124 Seconds\n",
      "Accuracy = 93.7% (937/1000) (classification)\n",
      "Running time: 27.92077639019135 Seconds\n",
      "training time: 25.136305221169096 Seconds\n",
      "Accuracy = 93.8% (938/1000) (classification)\n",
      "Running time: 28.52236580065346 Seconds\n",
      "training time: 25.481484466388792 Seconds\n",
      "Accuracy = 94.1% (941/1000) (classification)\n",
      "Running time: 28.93000225579999 Seconds\n",
      "training time: 25.727873507705226 Seconds\n",
      "Accuracy = 94.1% (941/1000) (classification)\n",
      "Running time: 29.12117081935321 Seconds\n",
      "training time: 26.137771293505466 Seconds\n",
      "Accuracy = 94.2% (942/1000) (classification)\n",
      "Running time: 29.656150530981904 Seconds\n",
      "training time: 26.58338143204128 Seconds\n",
      "Accuracy = 94% (940/1000) (classification)\n",
      "Running time: 30.166419950909585 Seconds\n",
      "training time: 27.27590209275786 Seconds\n",
      "Accuracy = 93.9% (939/1000) (classification)\n",
      "Running time: 31.245175413125253 Seconds\n",
      "training time: 27.76548175942935 Seconds\n",
      "Accuracy = 94% (940/1000) (classification)\n",
      "Running time: 31.36164579360502 Seconds\n",
      "training time: 27.791786913437136 Seconds\n",
      "Accuracy = 94.2% (942/1000) (classification)\n",
      "Running time: 31.434448472751683 Seconds\n",
      "training time: 28.287380992733233 Seconds\n",
      "Accuracy = 94.3% (943/1000) (classification)\n",
      "Running time: 31.91321096705815 Seconds\n",
      "training time: 28.694324115368545 Seconds\n",
      "Accuracy = 94.4% (944/1000) (classification)\n",
      "Running time: 32.50393816817177 Seconds\n",
      "training time: 29.069557645956593 Seconds\n",
      "Accuracy = 94.5% (945/1000) (classification)\n",
      "Running time: 32.639339884239234 Seconds\n",
      "training time: 29.770600568177542 Seconds\n",
      "Accuracy = 94.4% (944/1000) (classification)\n",
      "Running time: 33.283201244601514 Seconds\n"
     ]
    }
   ],
   "source": [
    "# 多项式核\n",
    "ac1,train_time1,total_time1 = check_time(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_svm(60000,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model supports probability estimates, but disabled in predicton.\n",
      "Accuracy = 12.6% (126/1000) (classification)\n",
      "Running time: 941.7631710461183 Seconds\n"
     ]
    }
   ],
   "source": [
    "start =time.clock()\n",
    "prob_3  = svm_problem(y_train_svm[:10000], x_train_svm[:10000])\n",
    "param_3 = svm_parameter('-t 2 -c 4 -b 1')\n",
    "model_3 = svm_train(prob_3, param_3)\n",
    "p_label_3, p_acc_3, p_val_3 = svm_predict(y_test_svm[:1000], x_test_svm[:1000], model_3)\n",
    "end = time.clock()\n",
    "print('Running time: %s Seconds'%(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 作图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy rate')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16e3bdfcbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pylab import *\n",
    "%matplotlib inline\n",
    "t = np.arange(700,10000., 100)\n",
    "plot(t, ac[7:], color=\"blue\", linewidth=2.5, linestyle=\"-\", label=\"linear\")\n",
    "plot(t, ac1[7:], color=\"red\",  linewidth=2.5, linestyle=\"-\", label=\"polynomial\")\n",
    "# plot(t, accuracy3[100:], color=\"green\",  linewidth=2.5, linestyle=\"-\", label=\"4 layer\")\n",
    "legend(loc='upper left')\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('accuracy rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'train time')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16e3f0c9940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = np.arange(700,10000., 100)\n",
    "plot(t, train_time[7:], color=\"blue\", linewidth=2.5, linestyle=\"-\", label=\"linear\")\n",
    "plot(t, train_time1[7:], color=\"red\",  linewidth=2.5, linestyle=\"-\", label=\"polynomial\")\n",
    "# plot(t, accuracy3[100:], color=\"green\",  linewidth=2.5, linestyle=\"-\", label=\"4 layer\")\n",
    "legend(loc='upper left')\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('train time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# 自动获取MNIST的数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1.0 轮 accuracy on test set: 0.9474\n",
      "第 2.0 轮 accuracy on test set: 0.9482\n",
      "第 3.0 轮 accuracy on test set: 0.9608\n",
      "第 4.0 轮 accuracy on test set: 0.9614\n",
      "第 5.0 轮 accuracy on test set: 0.9629\n",
      "第 6.0 轮 accuracy on test set: 0.9622\n",
      "第 7.0 轮 accuracy on test set: 0.9654\n",
      "第 8.0 轮 accuracy on test set: 0.9671\n",
      "第 9.0 轮 accuracy on test set: 0.9653\n",
      "最终 accuracy on test set: 0.9687\n"
     ]
    }
   ],
   "source": [
    "inputSize  = 784\n",
    "outputSize = 10\n",
    "hiddenSize = 89\n",
    "batchSize  = 1\n",
    "trainCycle = 600000\n",
    "# 输入层\n",
    "inputLayer = tf.placeholder(tf.float32, shape=[None, inputSize])\n",
    "# 隐藏层\n",
    "hiddenWeight = tf.Variable(tf.truncated_normal([inputSize, hiddenSize], mean=0, stddev=0.1))\n",
    "hiddenBias   = tf.Variable(tf.truncated_normal([hiddenSize]))\n",
    "hiddenLayer  = tf.add(tf.matmul(inputLayer, hiddenWeight), hiddenBias)\n",
    "hiddenLayer  = tf.nn.sigmoid(hiddenLayer)\n",
    "# 输出层\n",
    "outputWeight = tf.Variable(tf.truncated_normal([hiddenSize, outputSize], mean=0, stddev=0.1))\n",
    "outputBias   = tf.Variable(tf.truncated_normal([outputSize], mean=0, stddev=0.1))\n",
    "outputLayer  = tf.add(tf.matmul(hiddenLayer, outputWeight), outputBias)\n",
    "outputLayer  = tf.nn.sigmoid(outputLayer)\n",
    "# 标签\n",
    "outputLabel = tf.placeholder(tf.float32, shape=[None, outputSize])\n",
    "# 损失函数\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=outputLabel, logits=outputLayer))\n",
    "# 优化器\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "# 训练目标\n",
    "target = optimizer.minimize(loss)\n",
    "# 训练\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(trainCycle):\n",
    "        batch = mnist.train.next_batch(batchSize)\n",
    "        sess.run(target, feed_dict={inputLayer: batch[0], outputLabel: batch[1]})\n",
    "        if i%(60000/batchSize)==0 and i!=0:\n",
    "            corrected = tf.equal(tf.argmax(outputLabel, 1), tf.argmax(outputLayer, 1))\n",
    "            accuracy  = tf.reduce_mean(tf.cast(corrected, tf.float32))\n",
    "            accuracyValue = sess.run(accuracy, feed_dict={inputLayer: mnist.test.images, outputLabel: mnist.test.labels})\n",
    "            print(\"第\",i*batchSize/60000,\"轮\",\"accuracy on test set:\", accuracyValue)\n",
    "    # 测试\n",
    "    corrected = tf.equal(tf.argmax(outputLabel, 1), tf.argmax(outputLayer, 1))\n",
    "    accuracy  = tf.reduce_mean(tf.cast(corrected, tf.float32))\n",
    "    accuracyValue = sess.run(accuracy, feed_dict={inputLayer: mnist.test.images, outputLabel: mnist.test.labels})\n",
    "    print(\"最终 accuracy on test set:\", accuracyValue)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 100 张 accuracy on test set: 0.3353\n",
      "第 200 张 accuracy on test set: 0.4986\n",
      "第 300 张 accuracy on test set: 0.6658\n",
      "第 400 张 accuracy on test set: 0.6845\n",
      "第 500 张 accuracy on test set: 0.7586\n",
      "第 600 张 accuracy on test set: 0.797\n",
      "第 700 张 accuracy on test set: 0.7535\n",
      "第 800 张 accuracy on test set: 0.8012\n",
      "第 900 张 accuracy on test set: 0.8154\n",
      "第 1000 张 accuracy on test set: 0.82\n",
      "第 1100 张 accuracy on test set: 0.8206\n",
      "第 1200 张 accuracy on test set: 0.8331\n",
      "第 1300 张 accuracy on test set: 0.8426\n",
      "第 1400 张 accuracy on test set: 0.8324\n",
      "第 1500 张 accuracy on test set: 0.8377\n",
      "第 1600 张 accuracy on test set: 0.8485\n",
      "第 1700 张 accuracy on test set: 0.8581\n",
      "第 1800 张 accuracy on test set: 0.863\n",
      "第 1900 张 accuracy on test set: 0.8584\n",
      "第 2000 张 accuracy on test set: 0.8606\n",
      "第 2100 张 accuracy on test set: 0.8601\n",
      "第 2200 张 accuracy on test set: 0.8642\n",
      "第 2300 张 accuracy on test set: 0.8558\n",
      "第 2400 张 accuracy on test set: 0.8615\n",
      "第 2500 张 accuracy on test set: 0.867\n",
      "第 2600 张 accuracy on test set: 0.8619\n",
      "第 2700 张 accuracy on test set: 0.8609\n",
      "第 2800 张 accuracy on test set: 0.8596\n",
      "第 2900 张 accuracy on test set: 0.8669\n",
      "第 3000 张 accuracy on test set: 0.8668\n",
      "第 3100 张 accuracy on test set: 0.8703\n",
      "第 3200 张 accuracy on test set: 0.8681\n",
      "第 3300 张 accuracy on test set: 0.873\n",
      "第 3400 张 accuracy on test set: 0.8765\n",
      "第 3500 张 accuracy on test set: 0.8742\n",
      "第 3600 张 accuracy on test set: 0.8782\n",
      "第 3700 张 accuracy on test set: 0.8762\n",
      "第 3800 张 accuracy on test set: 0.8719\n",
      "第 3900 张 accuracy on test set: 0.8731\n",
      "第 4000 张 accuracy on test set: 0.8674\n",
      "第 4100 张 accuracy on test set: 0.8729\n",
      "第 4200 张 accuracy on test set: 0.8732\n",
      "第 4300 张 accuracy on test set: 0.8642\n",
      "第 4400 张 accuracy on test set: 0.8744\n",
      "第 4500 张 accuracy on test set: 0.8793\n",
      "第 4600 张 accuracy on test set: 0.8771\n",
      "第 4700 张 accuracy on test set: 0.8773\n",
      "第 4800 张 accuracy on test set: 0.8811\n",
      "第 4900 张 accuracy on test set: 0.8774\n",
      "第 5000 张 accuracy on test set: 0.8703\n",
      "第 5100 张 accuracy on test set: 0.8714\n",
      "第 5200 张 accuracy on test set: 0.8738\n",
      "第 5300 张 accuracy on test set: 0.8801\n",
      "第 5400 张 accuracy on test set: 0.8847\n",
      "第 5500 张 accuracy on test set: 0.8869\n",
      "第 5600 张 accuracy on test set: 0.8863\n",
      "第 5700 张 accuracy on test set: 0.8862\n",
      "第 5800 张 accuracy on test set: 0.878\n",
      "第 5900 张 accuracy on test set: 0.8845\n",
      "第 6000 张 accuracy on test set: 0.8843\n",
      "第 6100 张 accuracy on test set: 0.8896\n",
      "第 6200 张 accuracy on test set: 0.8845\n",
      "第 6300 张 accuracy on test set: 0.8842\n",
      "第 6400 张 accuracy on test set: 0.8914\n",
      "第 6500 张 accuracy on test set: 0.8882\n",
      "第 6600 张 accuracy on test set: 0.8907\n",
      "第 6700 张 accuracy on test set: 0.8895\n",
      "第 6800 张 accuracy on test set: 0.8901\n",
      "第 6900 张 accuracy on test set: 0.882\n",
      "第 7000 张 accuracy on test set: 0.872\n",
      "第 7100 张 accuracy on test set: 0.8865\n",
      "第 7200 张 accuracy on test set: 0.8948\n",
      "第 7300 张 accuracy on test set: 0.8919\n",
      "第 7400 张 accuracy on test set: 0.8904\n",
      "第 7500 张 accuracy on test set: 0.8867\n",
      "第 7600 张 accuracy on test set: 0.8895\n",
      "第 7700 张 accuracy on test set: 0.8923\n",
      "第 7800 张 accuracy on test set: 0.8935\n",
      "第 7900 张 accuracy on test set: 0.8936\n",
      "第 8000 张 accuracy on test set: 0.8927\n",
      "第 8100 张 accuracy on test set: 0.888\n",
      "第 8200 张 accuracy on test set: 0.8897\n",
      "第 8300 张 accuracy on test set: 0.8966\n",
      "第 8400 张 accuracy on test set: 0.8962\n",
      "第 8500 张 accuracy on test set: 0.8953\n",
      "第 8600 张 accuracy on test set: 0.8933\n",
      "第 8700 张 accuracy on test set: 0.8938\n",
      "第 8800 张 accuracy on test set: 0.8932\n",
      "第 8900 张 accuracy on test set: 0.8941\n",
      "第 9000 张 accuracy on test set: 0.8966\n",
      "第 9100 张 accuracy on test set: 0.8912\n",
      "第 9200 张 accuracy on test set: 0.8918\n",
      "第 9300 张 accuracy on test set: 0.8884\n",
      "第 9400 张 accuracy on test set: 0.8938\n",
      "第 9500 张 accuracy on test set: 0.8943\n",
      "第 9600 张 accuracy on test set: 0.8975\n",
      "第 9700 张 accuracy on test set: 0.8975\n",
      "第 9800 张 accuracy on test set: 0.8978\n",
      "第 9900 张 accuracy on test set: 0.8967\n",
      "第 10000 张 accuracy on test set: 0.8999\n",
      "第 10100 张 accuracy on test set: 0.8985\n",
      "第 10200 张 accuracy on test set: 0.8953\n",
      "第 10300 张 accuracy on test set: 0.8958\n",
      "第 10400 张 accuracy on test set: 0.8999\n",
      "第 10500 张 accuracy on test set: 0.8936\n",
      "第 10600 张 accuracy on test set: 0.8947\n",
      "第 10700 张 accuracy on test set: 0.8953\n",
      "第 10800 张 accuracy on test set: 0.8932\n",
      "第 10900 张 accuracy on test set: 0.8947\n",
      "第 11000 张 accuracy on test set: 0.8927\n",
      "第 11100 张 accuracy on test set: 0.897\n",
      "第 11200 张 accuracy on test set: 0.8962\n",
      "第 11300 张 accuracy on test set: 0.899\n",
      "第 11400 张 accuracy on test set: 0.9002\n",
      "第 11500 张 accuracy on test set: 0.8979\n",
      "第 11600 张 accuracy on test set: 0.8986\n",
      "第 11700 张 accuracy on test set: 0.9004\n",
      "第 11800 张 accuracy on test set: 0.8986\n",
      "第 11900 张 accuracy on test set: 0.9008\n",
      "第 12000 张 accuracy on test set: 0.8999\n",
      "第 12100 张 accuracy on test set: 0.8996\n",
      "第 12200 张 accuracy on test set: 0.8954\n",
      "第 12300 张 accuracy on test set: 0.891\n",
      "第 12400 张 accuracy on test set: 0.8997\n",
      "第 12500 张 accuracy on test set: 0.9006\n",
      "第 12600 张 accuracy on test set: 0.8987\n",
      "第 12700 张 accuracy on test set: 0.8981\n",
      "第 12800 张 accuracy on test set: 0.899\n",
      "第 12900 张 accuracy on test set: 0.899\n",
      "第 13000 张 accuracy on test set: 0.8934\n",
      "第 13100 张 accuracy on test set: 0.8982\n",
      "第 13200 张 accuracy on test set: 0.8989\n",
      "第 13300 张 accuracy on test set: 0.9004\n",
      "第 13400 张 accuracy on test set: 0.9011\n",
      "第 13500 张 accuracy on test set: 0.9012\n",
      "第 13600 张 accuracy on test set: 0.9\n",
      "第 13700 张 accuracy on test set: 0.8974\n",
      "第 13800 张 accuracy on test set: 0.8994\n",
      "第 13900 张 accuracy on test set: 0.8982\n",
      "第 14000 张 accuracy on test set: 0.9016\n",
      "第 14100 张 accuracy on test set: 0.8981\n",
      "第 14200 张 accuracy on test set: 0.9021\n",
      "第 14300 张 accuracy on test set: 0.9024\n",
      "第 14400 张 accuracy on test set: 0.9028\n",
      "第 14500 张 accuracy on test set: 0.9001\n",
      "第 14600 张 accuracy on test set: 0.9044\n",
      "第 14700 张 accuracy on test set: 0.9042\n",
      "第 14800 张 accuracy on test set: 0.9006\n",
      "第 14900 张 accuracy on test set: 0.905\n",
      "第 15000 张 accuracy on test set: 0.9013\n",
      "第 15100 张 accuracy on test set: 0.8974\n",
      "第 15200 张 accuracy on test set: 0.9031\n",
      "第 15300 张 accuracy on test set: 0.9037\n",
      "第 15400 张 accuracy on test set: 0.9034\n",
      "第 15500 张 accuracy on test set: 0.9037\n",
      "第 15600 张 accuracy on test set: 0.9016\n",
      "第 15700 张 accuracy on test set: 0.9049\n",
      "第 15800 张 accuracy on test set: 0.9025\n",
      "第 15900 张 accuracy on test set: 0.9024\n",
      "第 16000 张 accuracy on test set: 0.9038\n",
      "第 16100 张 accuracy on test set: 0.9017\n",
      "第 16200 张 accuracy on test set: 0.8979\n",
      "第 16300 张 accuracy on test set: 0.898\n",
      "第 16400 张 accuracy on test set: 0.9003\n",
      "第 16500 张 accuracy on test set: 0.9048\n",
      "第 16600 张 accuracy on test set: 0.9048\n",
      "第 16700 张 accuracy on test set: 0.9036\n",
      "第 16800 张 accuracy on test set: 0.9044\n",
      "第 16900 张 accuracy on test set: 0.9036\n",
      "第 17000 张 accuracy on test set: 0.9054\n",
      "第 17100 张 accuracy on test set: 0.9025\n",
      "第 17200 张 accuracy on test set: 0.9031\n",
      "第 17300 张 accuracy on test set: 0.9039\n",
      "第 17400 张 accuracy on test set: 0.903\n",
      "第 17500 张 accuracy on test set: 0.9058\n",
      "第 17600 张 accuracy on test set: 0.8999\n",
      "第 17700 张 accuracy on test set: 0.901\n",
      "第 17800 张 accuracy on test set: 0.9025\n",
      "第 17900 张 accuracy on test set: 0.904\n",
      "第 18000 张 accuracy on test set: 0.9028\n",
      "第 18100 张 accuracy on test set: 0.9059\n",
      "第 18200 张 accuracy on test set: 0.9061\n",
      "第 18300 张 accuracy on test set: 0.9055\n",
      "第 18400 张 accuracy on test set: 0.9041\n",
      "第 18500 张 accuracy on test set: 0.9055\n",
      "第 18600 张 accuracy on test set: 0.8988\n",
      "第 18700 张 accuracy on test set: 0.904\n",
      "第 18800 张 accuracy on test set: 0.9042\n",
      "第 18900 张 accuracy on test set: 0.9056\n",
      "第 19000 张 accuracy on test set: 0.9065\n",
      "第 19100 张 accuracy on test set: 0.9049\n",
      "第 19200 张 accuracy on test set: 0.9038\n",
      "第 19300 张 accuracy on test set: 0.9036\n",
      "第 19400 张 accuracy on test set: 0.9045\n",
      "第 19500 张 accuracy on test set: 0.9008\n",
      "第 19600 张 accuracy on test set: 0.9042\n",
      "第 19700 张 accuracy on test set: 0.9059\n",
      "第 19800 张 accuracy on test set: 0.9055\n",
      "第 19900 张 accuracy on test set: 0.8998\n",
      "第 20000 张 accuracy on test set: 0.9038\n",
      "第 20100 张 accuracy on test set: 0.9075\n",
      "第 20200 张 accuracy on test set: 0.9024\n",
      "第 20300 张 accuracy on test set: 0.9056\n",
      "第 20400 张 accuracy on test set: 0.905\n",
      "第 20500 张 accuracy on test set: 0.9059\n",
      "第 20600 张 accuracy on test set: 0.9071\n",
      "第 20700 张 accuracy on test set: 0.908\n",
      "第 20800 张 accuracy on test set: 0.9062\n",
      "第 20900 张 accuracy on test set: 0.9077\n",
      "第 21000 张 accuracy on test set: 0.9089\n",
      "第 21100 张 accuracy on test set: 0.9038\n",
      "第 21200 张 accuracy on test set: 0.9054\n",
      "第 21300 张 accuracy on test set: 0.9061\n",
      "第 21400 张 accuracy on test set: 0.905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 21500 张 accuracy on test set: 0.9058\n",
      "第 21600 张 accuracy on test set: 0.902\n",
      "第 21700 张 accuracy on test set: 0.9021\n",
      "第 21800 张 accuracy on test set: 0.8989\n",
      "第 21900 张 accuracy on test set: 0.9033\n",
      "第 22000 张 accuracy on test set: 0.9031\n",
      "第 22100 张 accuracy on test set: 0.9053\n",
      "第 22200 张 accuracy on test set: 0.9028\n",
      "第 22300 张 accuracy on test set: 0.9033\n",
      "第 22400 张 accuracy on test set: 0.9061\n",
      "第 22500 张 accuracy on test set: 0.9045\n",
      "第 22600 张 accuracy on test set: 0.9033\n",
      "第 22700 张 accuracy on test set: 0.9048\n",
      "第 22800 张 accuracy on test set: 0.9072\n",
      "第 22900 张 accuracy on test set: 0.9057\n",
      "第 23000 张 accuracy on test set: 0.905\n",
      "第 23100 张 accuracy on test set: 0.9046\n",
      "第 23200 张 accuracy on test set: 0.9053\n",
      "第 23300 张 accuracy on test set: 0.9071\n",
      "第 23400 张 accuracy on test set: 0.9087\n",
      "第 23500 张 accuracy on test set: 0.9087\n",
      "第 23600 张 accuracy on test set: 0.9073\n",
      "第 23700 张 accuracy on test set: 0.909\n",
      "第 23800 张 accuracy on test set: 0.9072\n",
      "第 23900 张 accuracy on test set: 0.9065\n",
      "第 24000 张 accuracy on test set: 0.9084\n",
      "第 24100 张 accuracy on test set: 0.9063\n",
      "第 24200 张 accuracy on test set: 0.9069\n",
      "第 24300 张 accuracy on test set: 0.9074\n",
      "第 24400 张 accuracy on test set: 0.9011\n",
      "第 24500 张 accuracy on test set: 0.902\n",
      "第 24600 张 accuracy on test set: 0.9058\n",
      "第 24700 张 accuracy on test set: 0.9052\n",
      "第 24800 张 accuracy on test set: 0.9045\n",
      "第 24900 张 accuracy on test set: 0.902\n",
      "第 25000 张 accuracy on test set: 0.9037\n",
      "第 25100 张 accuracy on test set: 0.9055\n",
      "第 25200 张 accuracy on test set: 0.9054\n",
      "第 25300 张 accuracy on test set: 0.9059\n",
      "第 25400 张 accuracy on test set: 0.9073\n",
      "第 25500 张 accuracy on test set: 0.9084\n",
      "第 25600 张 accuracy on test set: 0.907\n",
      "第 25700 张 accuracy on test set: 0.91\n",
      "第 25800 张 accuracy on test set: 0.9098\n",
      "第 25900 张 accuracy on test set: 0.9105\n",
      "第 26000 张 accuracy on test set: 0.9093\n",
      "第 26100 张 accuracy on test set: 0.9091\n",
      "第 26200 张 accuracy on test set: 0.9094\n",
      "第 26300 张 accuracy on test set: 0.906\n",
      "第 26400 张 accuracy on test set: 0.9087\n",
      "第 26500 张 accuracy on test set: 0.9062\n",
      "第 26600 张 accuracy on test set: 0.9054\n",
      "第 26700 张 accuracy on test set: 0.9053\n",
      "第 26800 张 accuracy on test set: 0.9037\n",
      "第 26900 张 accuracy on test set: 0.9062\n",
      "第 27000 张 accuracy on test set: 0.9054\n",
      "第 27100 张 accuracy on test set: 0.9074\n",
      "第 27200 张 accuracy on test set: 0.9052\n",
      "第 27300 张 accuracy on test set: 0.9089\n",
      "第 27400 张 accuracy on test set: 0.9064\n",
      "第 27500 张 accuracy on test set: 0.8994\n",
      "第 27600 张 accuracy on test set: 0.903\n",
      "第 27700 张 accuracy on test set: 0.9034\n",
      "第 27800 张 accuracy on test set: 0.9054\n",
      "第 27900 张 accuracy on test set: 0.9069\n",
      "第 28000 张 accuracy on test set: 0.91\n",
      "第 28100 张 accuracy on test set: 0.9088\n",
      "第 28200 张 accuracy on test set: 0.9075\n",
      "第 28300 张 accuracy on test set: 0.9116\n",
      "第 28400 张 accuracy on test set: 0.9099\n",
      "第 28500 张 accuracy on test set: 0.9063\n",
      "第 28600 张 accuracy on test set: 0.9082\n",
      "第 28700 张 accuracy on test set: 0.9107\n",
      "第 28800 张 accuracy on test set: 0.9097\n",
      "第 28900 张 accuracy on test set: 0.907\n",
      "第 29000 张 accuracy on test set: 0.9093\n",
      "第 29100 张 accuracy on test set: 0.9119\n",
      "第 29200 张 accuracy on test set: 0.9098\n",
      "第 29300 张 accuracy on test set: 0.9081\n",
      "第 29400 张 accuracy on test set: 0.9115\n",
      "第 29500 张 accuracy on test set: 0.9114\n",
      "第 29600 张 accuracy on test set: 0.912\n",
      "第 29700 张 accuracy on test set: 0.9091\n",
      "第 29800 张 accuracy on test set: 0.9118\n",
      "第 29900 张 accuracy on test set: 0.9099\n",
      "第 30000 张 accuracy on test set: 0.9105\n",
      "第 30100 张 accuracy on test set: 0.9103\n",
      "第 30200 张 accuracy on test set: 0.9077\n",
      "第 30300 张 accuracy on test set: 0.9116\n",
      "第 30400 张 accuracy on test set: 0.9125\n",
      "第 30500 张 accuracy on test set: 0.9089\n",
      "第 30600 张 accuracy on test set: 0.9098\n",
      "第 30700 张 accuracy on test set: 0.9109\n",
      "第 30800 张 accuracy on test set: 0.9102\n",
      "第 30900 张 accuracy on test set: 0.9118\n",
      "第 31000 张 accuracy on test set: 0.9109\n",
      "第 31100 张 accuracy on test set: 0.9109\n",
      "第 31200 张 accuracy on test set: 0.9114\n",
      "第 31300 张 accuracy on test set: 0.9079\n",
      "第 31400 张 accuracy on test set: 0.9116\n",
      "第 31500 张 accuracy on test set: 0.9121\n",
      "第 31600 张 accuracy on test set: 0.9098\n",
      "第 31700 张 accuracy on test set: 0.9097\n",
      "第 31800 张 accuracy on test set: 0.9044\n",
      "第 31900 张 accuracy on test set: 0.9066\n",
      "第 32000 张 accuracy on test set: 0.9058\n",
      "第 32100 张 accuracy on test set: 0.91\n",
      "第 32200 张 accuracy on test set: 0.9081\n",
      "第 32300 张 accuracy on test set: 0.9103\n",
      "第 32400 张 accuracy on test set: 0.9085\n",
      "第 32500 张 accuracy on test set: 0.9095\n",
      "第 32600 张 accuracy on test set: 0.9106\n",
      "第 32700 张 accuracy on test set: 0.9121\n",
      "第 32800 张 accuracy on test set: 0.9056\n",
      "第 32900 张 accuracy on test set: 0.9073\n",
      "第 33000 张 accuracy on test set: 0.9058\n",
      "第 33100 张 accuracy on test set: 0.9074\n",
      "第 33200 张 accuracy on test set: 0.9089\n",
      "第 33300 张 accuracy on test set: 0.9097\n",
      "第 33400 张 accuracy on test set: 0.9095\n",
      "第 33500 张 accuracy on test set: 0.9071\n",
      "第 33600 张 accuracy on test set: 0.9048\n",
      "第 33700 张 accuracy on test set: 0.9076\n",
      "第 33800 张 accuracy on test set: 0.9089\n",
      "第 33900 张 accuracy on test set: 0.9095\n",
      "第 34000 张 accuracy on test set: 0.9074\n",
      "第 34100 张 accuracy on test set: 0.9108\n",
      "第 34200 张 accuracy on test set: 0.9105\n",
      "第 34300 张 accuracy on test set: 0.9096\n",
      "第 34400 张 accuracy on test set: 0.9101\n",
      "第 34500 张 accuracy on test set: 0.9076\n",
      "第 34600 张 accuracy on test set: 0.911\n",
      "第 34700 张 accuracy on test set: 0.9096\n",
      "第 34800 张 accuracy on test set: 0.9091\n",
      "第 34900 张 accuracy on test set: 0.908\n",
      "第 35000 张 accuracy on test set: 0.9014\n",
      "第 35100 张 accuracy on test set: 0.9033\n",
      "第 35200 张 accuracy on test set: 0.9089\n",
      "第 35300 张 accuracy on test set: 0.9096\n",
      "第 35400 张 accuracy on test set: 0.91\n",
      "第 35500 张 accuracy on test set: 0.9083\n",
      "第 35600 张 accuracy on test set: 0.9109\n",
      "第 35700 张 accuracy on test set: 0.909\n",
      "第 35800 张 accuracy on test set: 0.9103\n",
      "第 35900 张 accuracy on test set: 0.9108\n",
      "第 36000 张 accuracy on test set: 0.9135\n",
      "第 36100 张 accuracy on test set: 0.9116\n",
      "第 36200 张 accuracy on test set: 0.9141\n",
      "第 36300 张 accuracy on test set: 0.9142\n",
      "第 36400 张 accuracy on test set: 0.9118\n",
      "第 36500 张 accuracy on test set: 0.9127\n",
      "第 36600 张 accuracy on test set: 0.9137\n",
      "第 36700 张 accuracy on test set: 0.9124\n",
      "第 36800 张 accuracy on test set: 0.9103\n",
      "第 36900 张 accuracy on test set: 0.9119\n",
      "第 37000 张 accuracy on test set: 0.9092\n",
      "第 37100 张 accuracy on test set: 0.9068\n",
      "第 37200 张 accuracy on test set: 0.9074\n",
      "第 37300 张 accuracy on test set: 0.9077\n",
      "第 37400 张 accuracy on test set: 0.9083\n",
      "第 37500 张 accuracy on test set: 0.9081\n",
      "第 37600 张 accuracy on test set: 0.9099\n",
      "第 37700 张 accuracy on test set: 0.9091\n",
      "第 37800 张 accuracy on test set: 0.9133\n",
      "第 37900 张 accuracy on test set: 0.9116\n",
      "第 38000 张 accuracy on test set: 0.9135\n",
      "第 38100 张 accuracy on test set: 0.9139\n",
      "第 38200 张 accuracy on test set: 0.9122\n",
      "第 38300 张 accuracy on test set: 0.9115\n",
      "第 38400 张 accuracy on test set: 0.9096\n",
      "第 38500 张 accuracy on test set: 0.9106\n",
      "第 38600 张 accuracy on test set: 0.9115\n",
      "第 38700 张 accuracy on test set: 0.9111\n",
      "第 38800 张 accuracy on test set: 0.9124\n",
      "第 38900 张 accuracy on test set: 0.9126\n",
      "第 39000 张 accuracy on test set: 0.9136\n",
      "第 39100 张 accuracy on test set: 0.9131\n",
      "第 39200 张 accuracy on test set: 0.9125\n",
      "第 39300 张 accuracy on test set: 0.9132\n",
      "第 39400 张 accuracy on test set: 0.9112\n",
      "第 39500 张 accuracy on test set: 0.9086\n",
      "第 39600 张 accuracy on test set: 0.9077\n",
      "第 39700 张 accuracy on test set: 0.9079\n",
      "第 39800 张 accuracy on test set: 0.9077\n",
      "第 39900 张 accuracy on test set: 0.9113\n",
      "第 40000 张 accuracy on test set: 0.9096\n",
      "第 40100 张 accuracy on test set: 0.9109\n",
      "第 40200 张 accuracy on test set: 0.9116\n",
      "第 40300 张 accuracy on test set: 0.9113\n",
      "第 40400 张 accuracy on test set: 0.9123\n",
      "第 40500 张 accuracy on test set: 0.911\n",
      "第 40600 张 accuracy on test set: 0.9115\n",
      "第 40700 张 accuracy on test set: 0.911\n",
      "第 40800 张 accuracy on test set: 0.9099\n",
      "第 40900 张 accuracy on test set: 0.9047\n",
      "第 41000 张 accuracy on test set: 0.9077\n",
      "第 41100 张 accuracy on test set: 0.9103\n",
      "第 41200 张 accuracy on test set: 0.9137\n",
      "第 41300 张 accuracy on test set: 0.9115\n",
      "第 41400 张 accuracy on test set: 0.9129\n",
      "第 41500 张 accuracy on test set: 0.9076\n",
      "第 41600 张 accuracy on test set: 0.9101\n",
      "第 41700 张 accuracy on test set: 0.9086\n",
      "第 41800 张 accuracy on test set: 0.9117\n",
      "第 41900 张 accuracy on test set: 0.9111\n",
      "第 42000 张 accuracy on test set: 0.9116\n",
      "第 42100 张 accuracy on test set: 0.9139\n",
      "第 42200 张 accuracy on test set: 0.9141\n",
      "第 42300 张 accuracy on test set: 0.9135\n",
      "第 42400 张 accuracy on test set: 0.9114\n",
      "第 42500 张 accuracy on test set: 0.9121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 42600 张 accuracy on test set: 0.9109\n",
      "第 42700 张 accuracy on test set: 0.9121\n",
      "第 42800 张 accuracy on test set: 0.9128\n",
      "第 42900 张 accuracy on test set: 0.9107\n",
      "第 43000 张 accuracy on test set: 0.9137\n",
      "第 43100 张 accuracy on test set: 0.9118\n",
      "第 43200 张 accuracy on test set: 0.912\n",
      "第 43300 张 accuracy on test set: 0.9126\n",
      "第 43400 张 accuracy on test set: 0.9127\n",
      "第 43500 张 accuracy on test set: 0.9133\n",
      "第 43600 张 accuracy on test set: 0.9127\n",
      "第 43700 张 accuracy on test set: 0.9108\n",
      "第 43800 张 accuracy on test set: 0.9112\n",
      "第 43900 张 accuracy on test set: 0.9098\n",
      "第 44000 张 accuracy on test set: 0.9103\n",
      "第 44100 张 accuracy on test set: 0.91\n",
      "第 44200 张 accuracy on test set: 0.9099\n",
      "第 44300 张 accuracy on test set: 0.9089\n",
      "第 44400 张 accuracy on test set: 0.9095\n",
      "第 44500 张 accuracy on test set: 0.9062\n",
      "第 44600 张 accuracy on test set: 0.9079\n",
      "第 44700 张 accuracy on test set: 0.91\n",
      "第 44800 张 accuracy on test set: 0.9136\n",
      "第 44900 张 accuracy on test set: 0.9131\n",
      "第 45000 张 accuracy on test set: 0.9109\n",
      "第 45100 张 accuracy on test set: 0.9111\n",
      "第 45200 张 accuracy on test set: 0.9133\n",
      "第 45300 张 accuracy on test set: 0.9128\n",
      "第 45400 张 accuracy on test set: 0.914\n",
      "第 45500 张 accuracy on test set: 0.9141\n",
      "第 45600 张 accuracy on test set: 0.9128\n",
      "第 45700 张 accuracy on test set: 0.9142\n",
      "第 45800 张 accuracy on test set: 0.9115\n",
      "第 45900 张 accuracy on test set: 0.9127\n",
      "第 46000 张 accuracy on test set: 0.9112\n",
      "第 46100 张 accuracy on test set: 0.9149\n",
      "第 46200 张 accuracy on test set: 0.9151\n",
      "第 46300 张 accuracy on test set: 0.9144\n",
      "第 46400 张 accuracy on test set: 0.9133\n",
      "第 46500 张 accuracy on test set: 0.9126\n",
      "第 46600 张 accuracy on test set: 0.9144\n",
      "第 46700 张 accuracy on test set: 0.9138\n",
      "第 46800 张 accuracy on test set: 0.9128\n",
      "第 46900 张 accuracy on test set: 0.9122\n",
      "第 47000 张 accuracy on test set: 0.909\n",
      "第 47100 张 accuracy on test set: 0.9102\n",
      "第 47200 张 accuracy on test set: 0.9106\n",
      "第 47300 张 accuracy on test set: 0.9122\n",
      "第 47400 张 accuracy on test set: 0.9086\n",
      "第 47500 张 accuracy on test set: 0.9107\n",
      "第 47600 张 accuracy on test set: 0.9084\n",
      "第 47700 张 accuracy on test set: 0.9078\n",
      "第 47800 张 accuracy on test set: 0.912\n",
      "第 47900 张 accuracy on test set: 0.9125\n",
      "第 48000 张 accuracy on test set: 0.9085\n",
      "第 48100 张 accuracy on test set: 0.9113\n",
      "第 48200 张 accuracy on test set: 0.9129\n",
      "第 48300 张 accuracy on test set: 0.9112\n",
      "第 48400 张 accuracy on test set: 0.9148\n",
      "第 48500 张 accuracy on test set: 0.9119\n",
      "第 48600 张 accuracy on test set: 0.9076\n",
      "第 48700 张 accuracy on test set: 0.9101\n",
      "第 48800 张 accuracy on test set: 0.9107\n",
      "第 48900 张 accuracy on test set: 0.9091\n",
      "第 49000 张 accuracy on test set: 0.9117\n",
      "第 49100 张 accuracy on test set: 0.9116\n",
      "第 49200 张 accuracy on test set: 0.9096\n",
      "第 49300 张 accuracy on test set: 0.9075\n",
      "第 49400 张 accuracy on test set: 0.9067\n",
      "第 49500 张 accuracy on test set: 0.9091\n",
      "第 49600 张 accuracy on test set: 0.9098\n",
      "第 49700 张 accuracy on test set: 0.91\n",
      "第 49800 张 accuracy on test set: 0.911\n",
      "第 49900 张 accuracy on test set: 0.9097\n",
      "第 50000 张 accuracy on test set: 0.9087\n",
      "第 50100 张 accuracy on test set: 0.9097\n",
      "第 50200 张 accuracy on test set: 0.9103\n",
      "第 50300 张 accuracy on test set: 0.9137\n",
      "第 50400 张 accuracy on test set: 0.914\n",
      "第 50500 张 accuracy on test set: 0.9115\n",
      "第 50600 张 accuracy on test set: 0.9087\n",
      "第 50700 张 accuracy on test set: 0.9093\n",
      "第 50800 张 accuracy on test set: 0.9081\n",
      "第 50900 张 accuracy on test set: 0.9092\n",
      "第 51000 张 accuracy on test set: 0.9125\n",
      "第 51100 张 accuracy on test set: 0.9126\n",
      "第 51200 张 accuracy on test set: 0.9132\n",
      "第 51300 张 accuracy on test set: 0.9121\n",
      "第 51400 张 accuracy on test set: 0.9119\n",
      "第 51500 张 accuracy on test set: 0.9138\n",
      "第 51600 张 accuracy on test set: 0.9124\n",
      "第 51700 张 accuracy on test set: 0.9105\n",
      "第 51800 张 accuracy on test set: 0.9106\n",
      "第 51900 张 accuracy on test set: 0.911\n",
      "第 52000 张 accuracy on test set: 0.9104\n",
      "第 52100 张 accuracy on test set: 0.9111\n",
      "第 52200 张 accuracy on test set: 0.9073\n",
      "第 52300 张 accuracy on test set: 0.9123\n",
      "第 52400 张 accuracy on test set: 0.9129\n",
      "第 52500 张 accuracy on test set: 0.9105\n",
      "第 52600 张 accuracy on test set: 0.9108\n",
      "第 52700 张 accuracy on test set: 0.9086\n",
      "第 52800 张 accuracy on test set: 0.9067\n",
      "第 52900 张 accuracy on test set: 0.9086\n",
      "第 53000 张 accuracy on test set: 0.9111\n",
      "第 53100 张 accuracy on test set: 0.9106\n",
      "第 53200 张 accuracy on test set: 0.9061\n",
      "第 53300 张 accuracy on test set: 0.9077\n",
      "第 53400 张 accuracy on test set: 0.9107\n",
      "第 53500 张 accuracy on test set: 0.9094\n",
      "第 53600 张 accuracy on test set: 0.9131\n",
      "第 53700 张 accuracy on test set: 0.9112\n",
      "第 53800 张 accuracy on test set: 0.9127\n",
      "第 53900 张 accuracy on test set: 0.9111\n",
      "第 54000 张 accuracy on test set: 0.9126\n",
      "第 54100 张 accuracy on test set: 0.9119\n",
      "第 54200 张 accuracy on test set: 0.9132\n",
      "第 54300 张 accuracy on test set: 0.914\n",
      "第 54400 张 accuracy on test set: 0.9152\n",
      "第 54500 张 accuracy on test set: 0.9141\n",
      "第 54600 张 accuracy on test set: 0.9131\n",
      "第 54700 张 accuracy on test set: 0.9121\n",
      "第 54800 张 accuracy on test set: 0.9113\n",
      "第 54900 张 accuracy on test set: 0.9112\n",
      "第 55000 张 accuracy on test set: 0.9082\n",
      "第 55100 张 accuracy on test set: 0.9052\n",
      "第 55200 张 accuracy on test set: 0.9087\n",
      "第 55300 张 accuracy on test set: 0.9122\n",
      "第 55400 张 accuracy on test set: 0.9124\n",
      "第 55500 张 accuracy on test set: 0.9117\n",
      "第 55600 张 accuracy on test set: 0.9149\n",
      "第 55700 张 accuracy on test set: 0.9127\n",
      "第 55800 张 accuracy on test set: 0.9116\n",
      "第 55900 张 accuracy on test set: 0.9138\n",
      "第 56000 张 accuracy on test set: 0.9124\n",
      "第 56100 张 accuracy on test set: 0.9132\n",
      "第 56200 张 accuracy on test set: 0.9117\n",
      "第 56300 张 accuracy on test set: 0.9123\n",
      "第 56400 张 accuracy on test set: 0.9142\n",
      "第 56500 张 accuracy on test set: 0.9157\n",
      "第 56600 张 accuracy on test set: 0.9163\n",
      "第 56700 张 accuracy on test set: 0.9171\n",
      "第 56800 张 accuracy on test set: 0.9169\n",
      "第 56900 张 accuracy on test set: 0.9167\n",
      "第 57000 张 accuracy on test set: 0.9142\n",
      "第 57100 张 accuracy on test set: 0.9163\n",
      "第 57200 张 accuracy on test set: 0.9168\n",
      "第 57300 张 accuracy on test set: 0.9147\n",
      "第 57400 张 accuracy on test set: 0.9158\n",
      "第 57500 张 accuracy on test set: 0.9165\n",
      "第 57600 张 accuracy on test set: 0.9161\n",
      "第 57700 张 accuracy on test set: 0.9152\n",
      "第 57800 张 accuracy on test set: 0.914\n",
      "第 57900 张 accuracy on test set: 0.9158\n",
      "第 58000 张 accuracy on test set: 0.9142\n",
      "第 58100 张 accuracy on test set: 0.911\n",
      "第 58200 张 accuracy on test set: 0.9105\n",
      "第 58300 张 accuracy on test set: 0.9127\n",
      "第 58400 张 accuracy on test set: 0.9136\n",
      "第 58500 张 accuracy on test set: 0.9145\n",
      "第 58600 张 accuracy on test set: 0.9128\n",
      "第 58700 张 accuracy on test set: 0.9134\n",
      "第 58800 张 accuracy on test set: 0.9137\n",
      "第 58900 张 accuracy on test set: 0.9144\n",
      "第 59000 张 accuracy on test set: 0.9148\n",
      "第 59100 张 accuracy on test set: 0.9139\n",
      "第 59200 张 accuracy on test set: 0.9109\n",
      "第 59300 张 accuracy on test set: 0.9098\n",
      "第 59400 张 accuracy on test set: 0.9108\n",
      "第 59500 张 accuracy on test set: 0.9096\n",
      "第 59600 张 accuracy on test set: 0.9114\n",
      "第 59700 张 accuracy on test set: 0.9149\n",
      "第 59800 张 accuracy on test set: 0.913\n",
      "第 59900 张 accuracy on test set: 0.9151\n",
      "最终 accuracy on test set: 0.9133\n"
     ]
    }
   ],
   "source": [
    "inputSize  = 784\n",
    "outputSize = 10\n",
    "batchSize  = 1\n",
    "trainCycle = 60000\n",
    "# 输入层\n",
    "inputLayer = tf.placeholder(tf.float32, shape=[None, inputSize])\n",
    "# 隐藏层\n",
    "\n",
    "# 输出层\n",
    "outputWeight = tf.Variable(tf.truncated_normal([inputSize, outputSize], mean=0, stddev=0.1))\n",
    "outputBias   = tf.Variable(tf.truncated_normal([outputSize], mean=0, stddev=0.1))\n",
    "outputLayer  = tf.add(tf.matmul(inputLayer, outputWeight), outputBias)\n",
    "outputLayer  = tf.nn.sigmoid(outputLayer)\n",
    "# 标签\n",
    "outputLabel = tf.placeholder(tf.float32, shape=[None, outputSize])\n",
    "# 损失函数\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=outputLabel, logits=outputLayer))\n",
    "# 优化器\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "# 训练目标\n",
    "target = optimizer.minimize(loss)\n",
    "# 训练\n",
    "accuracy_need2=[]\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(trainCycle):\n",
    "        batch = mnist.train.next_batch(batchSize)\n",
    "        sess.run(target, feed_dict={inputLayer: batch[0], outputLabel: batch[1]})\n",
    "        if i%(100)==0 and i!=0:\n",
    "            corrected = tf.equal(tf.argmax(outputLabel, 1), tf.argmax(outputLayer, 1))\n",
    "            accuracy  = tf.reduce_mean(tf.cast(corrected, tf.float32))\n",
    "            accuracyValue = sess.run(accuracy, feed_dict={inputLayer: mnist.test.images, outputLabel: mnist.test.labels})\n",
    "            print(\"第\",i,\"张\",\"accuracy on test set:\", accuracyValue)\n",
    "            accuracy_need2.append(accuracyValue)\n",
    "    # 测试\n",
    "    corrected = tf.equal(tf.argmax(outputLabel, 1), tf.argmax(outputLayer, 1))\n",
    "    accuracy  = tf.reduce_mean(tf.cast(corrected, tf.float32))\n",
    "    accuracyValue = sess.run(accuracy, feed_dict={inputLayer: mnist.test.images, outputLabel: mnist.test.labels})\n",
    "    print(\"最终 accuracy on test set:\", accuracyValue)\n",
    "    accuracy_need2.append(accuracyValue)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accuracy_need2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 100 张 accuracy on test set: 0.2714\n",
      "第 200 张 accuracy on test set: 0.4551\n",
      "第 300 张 accuracy on test set: 0.5896\n",
      "第 400 张 accuracy on test set: 0.6023\n",
      "第 500 张 accuracy on test set: 0.6891\n",
      "第 600 张 accuracy on test set: 0.7757\n",
      "第 700 张 accuracy on test set: 0.7455\n",
      "第 800 张 accuracy on test set: 0.7651\n",
      "第 900 张 accuracy on test set: 0.805\n",
      "第 1000 张 accuracy on test set: 0.7808\n",
      "第 1100 张 accuracy on test set: 0.8083\n",
      "第 1200 张 accuracy on test set: 0.8327\n",
      "第 1300 张 accuracy on test set: 0.7873\n",
      "第 1400 张 accuracy on test set: 0.8404\n",
      "第 1500 张 accuracy on test set: 0.8354\n",
      "第 1600 张 accuracy on test set: 0.8339\n",
      "第 1700 张 accuracy on test set: 0.8412\n",
      "第 1800 张 accuracy on test set: 0.8553\n",
      "第 1900 张 accuracy on test set: 0.855\n",
      "第 2000 张 accuracy on test set: 0.8369\n",
      "第 2100 张 accuracy on test set: 0.8585\n",
      "第 2200 张 accuracy on test set: 0.8541\n",
      "第 2300 张 accuracy on test set: 0.872\n",
      "第 2400 张 accuracy on test set: 0.8558\n",
      "第 2500 张 accuracy on test set: 0.8725\n",
      "第 2600 张 accuracy on test set: 0.8678\n",
      "第 2700 张 accuracy on test set: 0.8661\n",
      "第 2800 张 accuracy on test set: 0.8798\n",
      "第 2900 张 accuracy on test set: 0.8697\n",
      "第 3000 张 accuracy on test set: 0.8525\n",
      "第 3100 张 accuracy on test set: 0.8671\n",
      "第 3200 张 accuracy on test set: 0.8801\n",
      "第 3300 张 accuracy on test set: 0.8738\n",
      "第 3400 张 accuracy on test set: 0.8645\n",
      "第 3500 张 accuracy on test set: 0.8825\n",
      "第 3600 张 accuracy on test set: 0.8909\n",
      "第 3700 张 accuracy on test set: 0.8923\n",
      "第 3800 张 accuracy on test set: 0.8905\n",
      "第 3900 张 accuracy on test set: 0.8954\n",
      "第 4000 张 accuracy on test set: 0.8935\n",
      "第 4100 张 accuracy on test set: 0.895\n",
      "第 4200 张 accuracy on test set: 0.8903\n",
      "第 4300 张 accuracy on test set: 0.8871\n",
      "第 4400 张 accuracy on test set: 0.8904\n",
      "第 4500 张 accuracy on test set: 0.8983\n",
      "第 4600 张 accuracy on test set: 0.8987\n",
      "第 4700 张 accuracy on test set: 0.8884\n",
      "第 4800 张 accuracy on test set: 0.8916\n",
      "第 4900 张 accuracy on test set: 0.8958\n",
      "第 5000 张 accuracy on test set: 0.8964\n",
      "第 5100 张 accuracy on test set: 0.8914\n",
      "第 5200 张 accuracy on test set: 0.8919\n",
      "第 5300 张 accuracy on test set: 0.8937\n",
      "第 5400 张 accuracy on test set: 0.898\n",
      "第 5500 张 accuracy on test set: 0.899\n",
      "第 5600 张 accuracy on test set: 0.9015\n",
      "第 5700 张 accuracy on test set: 0.8999\n",
      "第 5800 张 accuracy on test set: 0.8972\n",
      "第 5900 张 accuracy on test set: 0.895\n",
      "第 6000 张 accuracy on test set: 0.9058\n",
      "第 6100 张 accuracy on test set: 0.8993\n",
      "第 6200 张 accuracy on test set: 0.9053\n",
      "第 6300 张 accuracy on test set: 0.9022\n",
      "第 6400 张 accuracy on test set: 0.8993\n",
      "第 6500 张 accuracy on test set: 0.9055\n",
      "第 6600 张 accuracy on test set: 0.8968\n",
      "第 6700 张 accuracy on test set: 0.9096\n",
      "第 6800 张 accuracy on test set: 0.9082\n",
      "第 6900 张 accuracy on test set: 0.9078\n",
      "第 7000 张 accuracy on test set: 0.8951\n",
      "第 7100 张 accuracy on test set: 0.9069\n",
      "第 7200 张 accuracy on test set: 0.9083\n",
      "第 7300 张 accuracy on test set: 0.9074\n",
      "第 7400 张 accuracy on test set: 0.9065\n",
      "第 7500 张 accuracy on test set: 0.907\n",
      "第 7600 张 accuracy on test set: 0.9095\n",
      "第 7700 张 accuracy on test set: 0.9096\n",
      "第 7800 张 accuracy on test set: 0.9116\n",
      "第 7900 张 accuracy on test set: 0.9096\n",
      "第 8000 张 accuracy on test set: 0.9056\n",
      "第 8100 张 accuracy on test set: 0.9112\n",
      "第 8200 张 accuracy on test set: 0.9065\n",
      "第 8300 张 accuracy on test set: 0.9092\n",
      "第 8400 张 accuracy on test set: 0.9077\n",
      "第 8500 张 accuracy on test set: 0.9095\n",
      "第 8600 张 accuracy on test set: 0.9062\n",
      "第 8700 张 accuracy on test set: 0.9103\n",
      "第 8800 张 accuracy on test set: 0.9116\n",
      "第 8900 张 accuracy on test set: 0.9103\n",
      "第 9000 张 accuracy on test set: 0.9113\n",
      "第 9100 张 accuracy on test set: 0.8986\n",
      "第 9200 张 accuracy on test set: 0.918\n",
      "第 9300 张 accuracy on test set: 0.9127\n",
      "第 9400 张 accuracy on test set: 0.913\n",
      "第 9500 张 accuracy on test set: 0.914\n",
      "第 9600 张 accuracy on test set: 0.9108\n",
      "第 9700 张 accuracy on test set: 0.9138\n",
      "第 9800 张 accuracy on test set: 0.9126\n",
      "第 9900 张 accuracy on test set: 0.9191\n",
      "第 10000 张 accuracy on test set: 0.916\n",
      "第 10100 张 accuracy on test set: 0.917\n",
      "第 10200 张 accuracy on test set: 0.9158\n",
      "第 10300 张 accuracy on test set: 0.9137\n",
      "第 10400 张 accuracy on test set: 0.9179\n",
      "第 10500 张 accuracy on test set: 0.9152\n",
      "第 10600 张 accuracy on test set: 0.9185\n",
      "第 10700 张 accuracy on test set: 0.916\n",
      "第 10800 张 accuracy on test set: 0.9092\n",
      "第 10900 张 accuracy on test set: 0.9182\n",
      "第 11000 张 accuracy on test set: 0.9173\n",
      "第 11100 张 accuracy on test set: 0.914\n",
      "第 11200 张 accuracy on test set: 0.9144\n",
      "第 11300 张 accuracy on test set: 0.915\n",
      "第 11400 张 accuracy on test set: 0.9163\n",
      "第 11500 张 accuracy on test set: 0.9165\n",
      "第 11600 张 accuracy on test set: 0.9175\n",
      "第 11700 张 accuracy on test set: 0.9188\n",
      "第 11800 张 accuracy on test set: 0.9206\n",
      "第 11900 张 accuracy on test set: 0.9108\n",
      "第 12000 张 accuracy on test set: 0.9094\n",
      "第 12100 张 accuracy on test set: 0.9154\n",
      "第 12200 张 accuracy on test set: 0.9161\n",
      "第 12300 张 accuracy on test set: 0.9187\n",
      "第 12400 张 accuracy on test set: 0.9159\n",
      "第 12500 张 accuracy on test set: 0.9137\n",
      "第 12600 张 accuracy on test set: 0.916\n",
      "第 12700 张 accuracy on test set: 0.9199\n",
      "第 12800 张 accuracy on test set: 0.9198\n",
      "第 12900 张 accuracy on test set: 0.9202\n",
      "第 13000 张 accuracy on test set: 0.9209\n",
      "第 13100 张 accuracy on test set: 0.9168\n",
      "第 13200 张 accuracy on test set: 0.9122\n",
      "第 13300 张 accuracy on test set: 0.9186\n",
      "第 13400 张 accuracy on test set: 0.9216\n",
      "第 13500 张 accuracy on test set: 0.92\n",
      "第 13600 张 accuracy on test set: 0.9213\n",
      "第 13700 张 accuracy on test set: 0.9204\n",
      "第 13800 张 accuracy on test set: 0.9173\n",
      "第 13900 张 accuracy on test set: 0.9206\n",
      "第 14000 张 accuracy on test set: 0.9172\n",
      "第 14100 张 accuracy on test set: 0.9157\n",
      "第 14200 张 accuracy on test set: 0.9128\n",
      "第 14300 张 accuracy on test set: 0.9114\n",
      "第 14400 张 accuracy on test set: 0.9207\n",
      "第 14500 张 accuracy on test set: 0.9209\n",
      "第 14600 张 accuracy on test set: 0.9151\n",
      "第 14700 张 accuracy on test set: 0.9182\n",
      "第 14800 张 accuracy on test set: 0.9235\n",
      "第 14900 张 accuracy on test set: 0.9186\n",
      "第 15000 张 accuracy on test set: 0.9206\n",
      "第 15100 张 accuracy on test set: 0.9205\n",
      "第 15200 张 accuracy on test set: 0.9203\n",
      "第 15300 张 accuracy on test set: 0.923\n",
      "第 15400 张 accuracy on test set: 0.9216\n",
      "第 15500 张 accuracy on test set: 0.9197\n",
      "第 15600 张 accuracy on test set: 0.9218\n",
      "第 15700 张 accuracy on test set: 0.9213\n",
      "第 15800 张 accuracy on test set: 0.9148\n",
      "第 15900 张 accuracy on test set: 0.9234\n",
      "第 16000 张 accuracy on test set: 0.9184\n",
      "第 16100 张 accuracy on test set: 0.922\n",
      "第 16200 张 accuracy on test set: 0.9202\n",
      "第 16300 张 accuracy on test set: 0.9239\n",
      "第 16400 张 accuracy on test set: 0.9242\n",
      "第 16500 张 accuracy on test set: 0.9236\n",
      "第 16600 张 accuracy on test set: 0.922\n",
      "第 16700 张 accuracy on test set: 0.9222\n",
      "第 16800 张 accuracy on test set: 0.9213\n",
      "第 16900 张 accuracy on test set: 0.9211\n",
      "第 17000 张 accuracy on test set: 0.9202\n",
      "第 17100 张 accuracy on test set: 0.919\n",
      "第 17200 张 accuracy on test set: 0.9226\n",
      "第 17300 张 accuracy on test set: 0.9237\n",
      "第 17400 张 accuracy on test set: 0.9235\n",
      "第 17500 张 accuracy on test set: 0.9241\n",
      "第 17600 张 accuracy on test set: 0.9233\n",
      "第 17700 张 accuracy on test set: 0.9247\n",
      "第 17800 张 accuracy on test set: 0.9255\n",
      "第 17900 张 accuracy on test set: 0.919\n",
      "第 18000 张 accuracy on test set: 0.9232\n",
      "第 18100 张 accuracy on test set: 0.9192\n",
      "第 18200 张 accuracy on test set: 0.9251\n",
      "第 18300 张 accuracy on test set: 0.929\n",
      "第 18400 张 accuracy on test set: 0.9269\n",
      "第 18500 张 accuracy on test set: 0.9248\n",
      "第 18600 张 accuracy on test set: 0.9282\n",
      "第 18700 张 accuracy on test set: 0.9267\n",
      "第 18800 张 accuracy on test set: 0.9244\n",
      "第 18900 张 accuracy on test set: 0.9213\n",
      "第 19000 张 accuracy on test set: 0.9271\n",
      "第 19100 张 accuracy on test set: 0.9285\n",
      "第 19200 张 accuracy on test set: 0.9274\n",
      "第 19300 张 accuracy on test set: 0.9262\n",
      "第 19400 张 accuracy on test set: 0.9261\n",
      "第 19500 张 accuracy on test set: 0.9276\n",
      "第 19600 张 accuracy on test set: 0.9268\n",
      "第 19700 张 accuracy on test set: 0.9275\n",
      "第 19800 张 accuracy on test set: 0.9299\n",
      "第 19900 张 accuracy on test set: 0.927\n",
      "第 20000 张 accuracy on test set: 0.9285\n",
      "第 20100 张 accuracy on test set: 0.9227\n",
      "第 20200 张 accuracy on test set: 0.9253\n",
      "第 20300 张 accuracy on test set: 0.9243\n",
      "第 20400 张 accuracy on test set: 0.9276\n",
      "第 20500 张 accuracy on test set: 0.9303\n",
      "第 20600 张 accuracy on test set: 0.9281\n",
      "第 20700 张 accuracy on test set: 0.9294\n",
      "第 20800 张 accuracy on test set: 0.9261\n",
      "第 20900 张 accuracy on test set: 0.9296\n",
      "第 21000 张 accuracy on test set: 0.9287\n",
      "第 21100 张 accuracy on test set: 0.9307\n",
      "第 21200 张 accuracy on test set: 0.9297\n",
      "第 21300 张 accuracy on test set: 0.9327\n",
      "第 21400 张 accuracy on test set: 0.9322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 21500 张 accuracy on test set: 0.9301\n",
      "第 21600 张 accuracy on test set: 0.9292\n",
      "第 21700 张 accuracy on test set: 0.9281\n",
      "第 21800 张 accuracy on test set: 0.9274\n",
      "第 21900 张 accuracy on test set: 0.9265\n",
      "第 22000 张 accuracy on test set: 0.9265\n",
      "第 22100 张 accuracy on test set: 0.9274\n",
      "第 22200 张 accuracy on test set: 0.9305\n",
      "第 22300 张 accuracy on test set: 0.9296\n",
      "第 22400 张 accuracy on test set: 0.9307\n",
      "第 22500 张 accuracy on test set: 0.9292\n",
      "第 22600 张 accuracy on test set: 0.9221\n",
      "第 22700 张 accuracy on test set: 0.9313\n",
      "第 22800 张 accuracy on test set: 0.9291\n",
      "第 22900 张 accuracy on test set: 0.931\n",
      "第 23000 张 accuracy on test set: 0.9249\n",
      "第 23100 张 accuracy on test set: 0.9285\n",
      "第 23200 张 accuracy on test set: 0.9273\n",
      "第 23300 张 accuracy on test set: 0.9271\n",
      "第 23400 张 accuracy on test set: 0.9289\n",
      "第 23500 张 accuracy on test set: 0.9321\n",
      "第 23600 张 accuracy on test set: 0.931\n",
      "第 23700 张 accuracy on test set: 0.9324\n",
      "第 23800 张 accuracy on test set: 0.9304\n",
      "第 23900 张 accuracy on test set: 0.926\n",
      "第 24000 张 accuracy on test set: 0.9287\n",
      "第 24100 张 accuracy on test set: 0.9324\n",
      "第 24200 张 accuracy on test set: 0.9317\n",
      "第 24300 张 accuracy on test set: 0.9308\n",
      "第 24400 张 accuracy on test set: 0.9285\n",
      "第 24500 张 accuracy on test set: 0.9337\n",
      "第 24600 张 accuracy on test set: 0.9309\n",
      "第 24700 张 accuracy on test set: 0.9334\n",
      "第 24800 张 accuracy on test set: 0.9332\n",
      "第 24900 张 accuracy on test set: 0.9339\n",
      "第 25000 张 accuracy on test set: 0.9342\n",
      "第 25100 张 accuracy on test set: 0.9337\n",
      "第 25200 张 accuracy on test set: 0.9296\n",
      "第 25300 张 accuracy on test set: 0.9293\n",
      "第 25400 张 accuracy on test set: 0.9321\n",
      "第 25500 张 accuracy on test set: 0.9318\n",
      "第 25600 张 accuracy on test set: 0.9322\n",
      "第 25700 张 accuracy on test set: 0.932\n",
      "第 25800 张 accuracy on test set: 0.9307\n",
      "第 25900 张 accuracy on test set: 0.9317\n",
      "第 26000 张 accuracy on test set: 0.9315\n",
      "第 26100 张 accuracy on test set: 0.9348\n",
      "第 26200 张 accuracy on test set: 0.9325\n",
      "第 26300 张 accuracy on test set: 0.9316\n",
      "第 26400 张 accuracy on test set: 0.9291\n",
      "第 26500 张 accuracy on test set: 0.9326\n",
      "第 26600 张 accuracy on test set: 0.9317\n",
      "第 26700 张 accuracy on test set: 0.9316\n",
      "第 26800 张 accuracy on test set: 0.9307\n",
      "第 26900 张 accuracy on test set: 0.9317\n",
      "第 27000 张 accuracy on test set: 0.9305\n",
      "第 27100 张 accuracy on test set: 0.9274\n",
      "第 27200 张 accuracy on test set: 0.927\n",
      "第 27300 张 accuracy on test set: 0.9307\n",
      "第 27400 张 accuracy on test set: 0.9335\n",
      "第 27500 张 accuracy on test set: 0.9321\n",
      "第 27600 张 accuracy on test set: 0.9297\n",
      "第 27700 张 accuracy on test set: 0.9348\n",
      "第 27800 张 accuracy on test set: 0.9325\n",
      "第 27900 张 accuracy on test set: 0.9356\n",
      "第 28000 张 accuracy on test set: 0.9327\n",
      "第 28100 张 accuracy on test set: 0.9324\n",
      "第 28200 张 accuracy on test set: 0.9324\n",
      "第 28300 张 accuracy on test set: 0.935\n",
      "第 28400 张 accuracy on test set: 0.9348\n",
      "第 28500 张 accuracy on test set: 0.9321\n",
      "第 28600 张 accuracy on test set: 0.9316\n",
      "第 28700 张 accuracy on test set: 0.9328\n",
      "第 28800 张 accuracy on test set: 0.9318\n",
      "第 28900 张 accuracy on test set: 0.9324\n",
      "第 29000 张 accuracy on test set: 0.9335\n",
      "第 29100 张 accuracy on test set: 0.9341\n",
      "第 29200 张 accuracy on test set: 0.9348\n",
      "第 29300 张 accuracy on test set: 0.9354\n",
      "第 29400 张 accuracy on test set: 0.9324\n",
      "第 29500 张 accuracy on test set: 0.9277\n",
      "第 29600 张 accuracy on test set: 0.9334\n",
      "第 29700 张 accuracy on test set: 0.9313\n",
      "第 29800 张 accuracy on test set: 0.9328\n",
      "第 29900 张 accuracy on test set: 0.9355\n",
      "第 30000 张 accuracy on test set: 0.9335\n",
      "第 30100 张 accuracy on test set: 0.9351\n",
      "第 30200 张 accuracy on test set: 0.9333\n",
      "第 30300 张 accuracy on test set: 0.9344\n",
      "第 30400 张 accuracy on test set: 0.9352\n",
      "第 30500 张 accuracy on test set: 0.9331\n",
      "第 30600 张 accuracy on test set: 0.9349\n",
      "第 30700 张 accuracy on test set: 0.9352\n",
      "第 30800 张 accuracy on test set: 0.9347\n",
      "第 30900 张 accuracy on test set: 0.9333\n",
      "第 31000 张 accuracy on test set: 0.9282\n",
      "第 31100 张 accuracy on test set: 0.9323\n",
      "第 31200 张 accuracy on test set: 0.9366\n",
      "第 31300 张 accuracy on test set: 0.9312\n",
      "第 31400 张 accuracy on test set: 0.936\n",
      "第 31500 张 accuracy on test set: 0.9321\n",
      "第 31600 张 accuracy on test set: 0.9356\n",
      "第 31700 张 accuracy on test set: 0.9371\n",
      "第 31800 张 accuracy on test set: 0.9331\n",
      "第 31900 张 accuracy on test set: 0.9335\n",
      "第 32000 张 accuracy on test set: 0.9325\n",
      "第 32100 张 accuracy on test set: 0.9304\n",
      "第 32200 张 accuracy on test set: 0.9334\n",
      "第 32300 张 accuracy on test set: 0.9365\n",
      "第 32400 张 accuracy on test set: 0.9301\n",
      "第 32500 张 accuracy on test set: 0.9366\n",
      "第 32600 张 accuracy on test set: 0.9387\n",
      "第 32700 张 accuracy on test set: 0.9397\n",
      "第 32800 张 accuracy on test set: 0.9371\n",
      "第 32900 张 accuracy on test set: 0.9305\n",
      "第 33000 张 accuracy on test set: 0.9372\n",
      "第 33100 张 accuracy on test set: 0.9401\n",
      "第 33200 张 accuracy on test set: 0.9399\n",
      "第 33300 张 accuracy on test set: 0.938\n",
      "第 33400 张 accuracy on test set: 0.9406\n",
      "第 33500 张 accuracy on test set: 0.9405\n",
      "第 33600 张 accuracy on test set: 0.9316\n",
      "第 33700 张 accuracy on test set: 0.936\n",
      "第 33800 张 accuracy on test set: 0.9358\n",
      "第 33900 张 accuracy on test set: 0.937\n",
      "第 34000 张 accuracy on test set: 0.9364\n",
      "第 34100 张 accuracy on test set: 0.9404\n",
      "第 34200 张 accuracy on test set: 0.9376\n",
      "第 34300 张 accuracy on test set: 0.9335\n",
      "第 34400 张 accuracy on test set: 0.937\n",
      "第 34500 张 accuracy on test set: 0.9395\n",
      "第 34600 张 accuracy on test set: 0.9401\n",
      "第 34700 张 accuracy on test set: 0.9387\n",
      "第 34800 张 accuracy on test set: 0.9375\n",
      "第 34900 张 accuracy on test set: 0.9357\n",
      "第 35000 张 accuracy on test set: 0.9375\n",
      "第 35100 张 accuracy on test set: 0.9348\n",
      "第 35200 张 accuracy on test set: 0.9327\n",
      "第 35300 张 accuracy on test set: 0.9318\n",
      "第 35400 张 accuracy on test set: 0.9373\n",
      "第 35500 张 accuracy on test set: 0.939\n",
      "第 35600 张 accuracy on test set: 0.9366\n",
      "第 35700 张 accuracy on test set: 0.9389\n",
      "第 35800 张 accuracy on test set: 0.9394\n",
      "第 35900 张 accuracy on test set: 0.9404\n",
      "第 36000 张 accuracy on test set: 0.9403\n",
      "第 36100 张 accuracy on test set: 0.9399\n",
      "第 36200 张 accuracy on test set: 0.9395\n",
      "第 36300 张 accuracy on test set: 0.9384\n",
      "第 36400 张 accuracy on test set: 0.9336\n",
      "第 36500 张 accuracy on test set: 0.9342\n",
      "第 36600 张 accuracy on test set: 0.9359\n",
      "第 36700 张 accuracy on test set: 0.9389\n",
      "第 36800 张 accuracy on test set: 0.9384\n",
      "第 36900 张 accuracy on test set: 0.9389\n",
      "第 37000 张 accuracy on test set: 0.9349\n",
      "第 37100 张 accuracy on test set: 0.9378\n",
      "第 37200 张 accuracy on test set: 0.9376\n",
      "第 37300 张 accuracy on test set: 0.9359\n",
      "第 37400 张 accuracy on test set: 0.9381\n",
      "第 37500 张 accuracy on test set: 0.9395\n",
      "第 37600 张 accuracy on test set: 0.9378\n",
      "第 37700 张 accuracy on test set: 0.9351\n",
      "第 37800 张 accuracy on test set: 0.9375\n",
      "第 37900 张 accuracy on test set: 0.937\n",
      "第 38000 张 accuracy on test set: 0.9394\n",
      "第 38100 张 accuracy on test set: 0.9404\n",
      "第 38200 张 accuracy on test set: 0.9401\n",
      "第 38300 张 accuracy on test set: 0.9381\n",
      "第 38400 张 accuracy on test set: 0.9363\n",
      "第 38500 张 accuracy on test set: 0.9382\n",
      "第 38600 张 accuracy on test set: 0.9393\n",
      "第 38700 张 accuracy on test set: 0.9382\n",
      "第 38800 张 accuracy on test set: 0.939\n",
      "第 38900 张 accuracy on test set: 0.935\n",
      "第 39000 张 accuracy on test set: 0.9385\n",
      "第 39100 张 accuracy on test set: 0.9346\n",
      "第 39200 张 accuracy on test set: 0.9382\n",
      "第 39300 张 accuracy on test set: 0.9419\n",
      "第 39400 张 accuracy on test set: 0.9382\n",
      "第 39500 张 accuracy on test set: 0.9398\n",
      "第 39600 张 accuracy on test set: 0.9398\n",
      "第 39700 张 accuracy on test set: 0.9364\n",
      "第 39800 张 accuracy on test set: 0.9349\n",
      "第 39900 张 accuracy on test set: 0.9404\n",
      "第 40000 张 accuracy on test set: 0.9371\n",
      "第 40100 张 accuracy on test set: 0.9346\n",
      "第 40200 张 accuracy on test set: 0.9404\n",
      "第 40300 张 accuracy on test set: 0.938\n",
      "第 40400 张 accuracy on test set: 0.9391\n",
      "第 40500 张 accuracy on test set: 0.9403\n",
      "第 40600 张 accuracy on test set: 0.9379\n",
      "第 40700 张 accuracy on test set: 0.9398\n",
      "第 40800 张 accuracy on test set: 0.9371\n",
      "第 40900 张 accuracy on test set: 0.9398\n",
      "第 41000 张 accuracy on test set: 0.9387\n",
      "第 41100 张 accuracy on test set: 0.9375\n",
      "第 41200 张 accuracy on test set: 0.9392\n",
      "第 41300 张 accuracy on test set: 0.9393\n",
      "第 41400 张 accuracy on test set: 0.9397\n",
      "第 41500 张 accuracy on test set: 0.9385\n",
      "第 41600 张 accuracy on test set: 0.9381\n",
      "第 41700 张 accuracy on test set: 0.9394\n",
      "第 41800 张 accuracy on test set: 0.9393\n",
      "第 41900 张 accuracy on test set: 0.9403\n",
      "第 42000 张 accuracy on test set: 0.9397\n",
      "第 42100 张 accuracy on test set: 0.939\n",
      "第 42200 张 accuracy on test set: 0.9398\n",
      "第 42300 张 accuracy on test set: 0.9384\n",
      "第 42400 张 accuracy on test set: 0.9408\n",
      "第 42500 张 accuracy on test set: 0.9409\n",
      "第 42600 张 accuracy on test set: 0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 42700 张 accuracy on test set: 0.9416\n",
      "第 42800 张 accuracy on test set: 0.9427\n",
      "第 42900 张 accuracy on test set: 0.9417\n",
      "第 43000 张 accuracy on test set: 0.9433\n",
      "第 43100 张 accuracy on test set: 0.9428\n",
      "第 43200 张 accuracy on test set: 0.943\n",
      "第 43300 张 accuracy on test set: 0.9391\n",
      "第 43400 张 accuracy on test set: 0.9424\n",
      "第 43500 张 accuracy on test set: 0.942\n",
      "第 43600 张 accuracy on test set: 0.9428\n",
      "第 43700 张 accuracy on test set: 0.9441\n",
      "第 43800 张 accuracy on test set: 0.943\n",
      "第 43900 张 accuracy on test set: 0.9414\n",
      "第 44000 张 accuracy on test set: 0.9432\n",
      "第 44100 张 accuracy on test set: 0.9425\n",
      "第 44200 张 accuracy on test set: 0.9405\n",
      "第 44300 张 accuracy on test set: 0.9395\n",
      "第 44400 张 accuracy on test set: 0.943\n",
      "第 44500 张 accuracy on test set: 0.9416\n",
      "第 44600 张 accuracy on test set: 0.9415\n",
      "第 44700 张 accuracy on test set: 0.9406\n",
      "第 44800 张 accuracy on test set: 0.943\n",
      "第 44900 张 accuracy on test set: 0.9445\n",
      "第 45000 张 accuracy on test set: 0.9461\n",
      "第 45100 张 accuracy on test set: 0.9396\n",
      "第 45200 张 accuracy on test set: 0.9379\n",
      "第 45300 张 accuracy on test set: 0.9419\n",
      "第 45400 张 accuracy on test set: 0.9402\n",
      "第 45500 张 accuracy on test set: 0.9422\n",
      "第 45600 张 accuracy on test set: 0.9438\n",
      "第 45700 张 accuracy on test set: 0.9416\n",
      "第 45800 张 accuracy on test set: 0.9392\n",
      "第 45900 张 accuracy on test set: 0.9429\n",
      "第 46000 张 accuracy on test set: 0.9417\n",
      "第 46100 张 accuracy on test set: 0.9429\n",
      "第 46200 张 accuracy on test set: 0.944\n",
      "第 46300 张 accuracy on test set: 0.9392\n",
      "第 46400 张 accuracy on test set: 0.9389\n",
      "第 46500 张 accuracy on test set: 0.9421\n",
      "第 46600 张 accuracy on test set: 0.9415\n",
      "第 46700 张 accuracy on test set: 0.9403\n",
      "第 46800 张 accuracy on test set: 0.942\n",
      "第 46900 张 accuracy on test set: 0.9424\n",
      "第 47000 张 accuracy on test set: 0.942\n",
      "第 47100 张 accuracy on test set: 0.9433\n",
      "第 47200 张 accuracy on test set: 0.9432\n",
      "第 47300 张 accuracy on test set: 0.9425\n",
      "第 47400 张 accuracy on test set: 0.9413\n",
      "第 47500 张 accuracy on test set: 0.9442\n",
      "第 47600 张 accuracy on test set: 0.9413\n",
      "第 47700 张 accuracy on test set: 0.9436\n",
      "第 47800 张 accuracy on test set: 0.9429\n",
      "第 47900 张 accuracy on test set: 0.944\n",
      "第 48000 张 accuracy on test set: 0.9409\n",
      "第 48100 张 accuracy on test set: 0.9395\n",
      "第 48200 张 accuracy on test set: 0.9412\n",
      "第 48300 张 accuracy on test set: 0.9428\n",
      "第 48400 张 accuracy on test set: 0.9412\n",
      "第 48500 张 accuracy on test set: 0.9411\n",
      "第 48600 张 accuracy on test set: 0.9419\n",
      "第 48700 张 accuracy on test set: 0.9433\n",
      "第 48800 张 accuracy on test set: 0.9452\n",
      "第 48900 张 accuracy on test set: 0.9447\n",
      "第 49000 张 accuracy on test set: 0.9443\n",
      "第 49100 张 accuracy on test set: 0.9423\n",
      "第 49200 张 accuracy on test set: 0.9448\n",
      "第 49300 张 accuracy on test set: 0.9415\n",
      "第 49400 张 accuracy on test set: 0.9419\n",
      "第 49500 张 accuracy on test set: 0.9434\n",
      "第 49600 张 accuracy on test set: 0.9415\n",
      "第 49700 张 accuracy on test set: 0.9414\n",
      "第 49800 张 accuracy on test set: 0.9426\n",
      "第 49900 张 accuracy on test set: 0.9426\n",
      "第 50000 张 accuracy on test set: 0.9402\n",
      "第 50100 张 accuracy on test set: 0.9466\n",
      "第 50200 张 accuracy on test set: 0.9476\n",
      "第 50300 张 accuracy on test set: 0.9479\n",
      "第 50400 张 accuracy on test set: 0.9479\n",
      "第 50500 张 accuracy on test set: 0.9467\n",
      "第 50600 张 accuracy on test set: 0.9456\n",
      "第 50700 张 accuracy on test set: 0.9365\n",
      "第 50800 张 accuracy on test set: 0.9445\n",
      "第 50900 张 accuracy on test set: 0.9433\n",
      "第 51000 张 accuracy on test set: 0.9423\n",
      "第 51100 张 accuracy on test set: 0.943\n",
      "第 51200 张 accuracy on test set: 0.9437\n",
      "第 51300 张 accuracy on test set: 0.9458\n",
      "第 51400 张 accuracy on test set: 0.9447\n",
      "第 51500 张 accuracy on test set: 0.9456\n",
      "第 51600 张 accuracy on test set: 0.947\n",
      "第 51700 张 accuracy on test set: 0.9406\n",
      "第 51800 张 accuracy on test set: 0.9466\n",
      "第 51900 张 accuracy on test set: 0.9396\n",
      "第 52000 张 accuracy on test set: 0.9415\n",
      "第 52100 张 accuracy on test set: 0.9417\n",
      "第 52200 张 accuracy on test set: 0.941\n",
      "第 52300 张 accuracy on test set: 0.9435\n",
      "第 52400 张 accuracy on test set: 0.9426\n",
      "第 52500 张 accuracy on test set: 0.9422\n",
      "第 52600 张 accuracy on test set: 0.9447\n",
      "第 52700 张 accuracy on test set: 0.9466\n",
      "第 52800 张 accuracy on test set: 0.9456\n",
      "第 52900 张 accuracy on test set: 0.9453\n",
      "第 53000 张 accuracy on test set: 0.9436\n",
      "第 53100 张 accuracy on test set: 0.9441\n",
      "第 53200 张 accuracy on test set: 0.9436\n",
      "第 53300 张 accuracy on test set: 0.9438\n",
      "第 53400 张 accuracy on test set: 0.9443\n",
      "第 53500 张 accuracy on test set: 0.9457\n",
      "第 53600 张 accuracy on test set: 0.9444\n",
      "第 53700 张 accuracy on test set: 0.943\n",
      "第 53800 张 accuracy on test set: 0.9431\n",
      "第 53900 张 accuracy on test set: 0.9483\n",
      "第 54000 张 accuracy on test set: 0.946\n",
      "第 54100 张 accuracy on test set: 0.9481\n",
      "第 54200 张 accuracy on test set: 0.947\n",
      "第 54300 张 accuracy on test set: 0.9457\n",
      "第 54400 张 accuracy on test set: 0.9483\n",
      "第 54500 张 accuracy on test set: 0.9482\n",
      "第 54600 张 accuracy on test set: 0.9445\n",
      "第 54700 张 accuracy on test set: 0.9452\n",
      "第 54800 张 accuracy on test set: 0.9464\n",
      "第 54900 张 accuracy on test set: 0.9454\n",
      "第 55000 张 accuracy on test set: 0.9458\n",
      "第 55100 张 accuracy on test set: 0.9427\n",
      "第 55200 张 accuracy on test set: 0.9425\n",
      "第 55300 张 accuracy on test set: 0.943\n",
      "第 55400 张 accuracy on test set: 0.944\n",
      "第 55500 张 accuracy on test set: 0.9467\n",
      "第 55600 张 accuracy on test set: 0.9469\n",
      "第 55700 张 accuracy on test set: 0.9479\n",
      "第 55800 张 accuracy on test set: 0.947\n",
      "第 55900 张 accuracy on test set: 0.9485\n",
      "第 56000 张 accuracy on test set: 0.9488\n",
      "第 56100 张 accuracy on test set: 0.9471\n",
      "第 56200 张 accuracy on test set: 0.9461\n",
      "第 56300 张 accuracy on test set: 0.9417\n",
      "第 56400 张 accuracy on test set: 0.9441\n",
      "第 56500 张 accuracy on test set: 0.9401\n",
      "第 56600 张 accuracy on test set: 0.9436\n",
      "第 56700 张 accuracy on test set: 0.9475\n",
      "第 56800 张 accuracy on test set: 0.947\n",
      "第 56900 张 accuracy on test set: 0.9464\n",
      "第 57000 张 accuracy on test set: 0.9455\n",
      "第 57100 张 accuracy on test set: 0.9449\n",
      "第 57200 张 accuracy on test set: 0.9461\n",
      "第 57300 张 accuracy on test set: 0.9474\n",
      "第 57400 张 accuracy on test set: 0.9452\n",
      "第 57500 张 accuracy on test set: 0.9443\n",
      "第 57600 张 accuracy on test set: 0.948\n",
      "第 57700 张 accuracy on test set: 0.9488\n",
      "第 57800 张 accuracy on test set: 0.9494\n",
      "第 57900 张 accuracy on test set: 0.949\n",
      "第 58000 张 accuracy on test set: 0.9461\n",
      "第 58100 张 accuracy on test set: 0.944\n",
      "第 58200 张 accuracy on test set: 0.9474\n",
      "第 58300 张 accuracy on test set: 0.9481\n",
      "第 58400 张 accuracy on test set: 0.9489\n",
      "第 58500 张 accuracy on test set: 0.9479\n",
      "第 58600 张 accuracy on test set: 0.948\n",
      "第 58700 张 accuracy on test set: 0.9461\n",
      "第 58800 张 accuracy on test set: 0.9476\n",
      "第 58900 张 accuracy on test set: 0.9488\n",
      "第 59000 张 accuracy on test set: 0.9489\n",
      "第 59100 张 accuracy on test set: 0.9474\n",
      "第 59200 张 accuracy on test set: 0.9496\n",
      "第 59300 张 accuracy on test set: 0.9465\n",
      "第 59400 张 accuracy on test set: 0.945\n",
      "第 59500 张 accuracy on test set: 0.9462\n",
      "第 59600 张 accuracy on test set: 0.9441\n",
      "第 59700 张 accuracy on test set: 0.9487\n",
      "第 59800 张 accuracy on test set: 0.946\n",
      "第 59900 张 accuracy on test set: 0.9481\n",
      "最终 accuracy on test set: 0.9491\n"
     ]
    }
   ],
   "source": [
    "inputSize  = 784\n",
    "outputSize = 10\n",
    "hiddenSize = 89\n",
    "batchSize  = 1\n",
    "trainCycle = 60000\n",
    "# 输入层\n",
    "inputLayer = tf.placeholder(tf.float32, shape=[None, inputSize])\n",
    "# 隐藏层\n",
    "hiddenWeight = tf.Variable(tf.truncated_normal([inputSize, hiddenSize], mean=0, stddev=0.1))\n",
    "hiddenBias   = tf.Variable(tf.truncated_normal([hiddenSize]))\n",
    "hiddenLayer  = tf.add(tf.matmul(inputLayer, hiddenWeight), hiddenBias)\n",
    "hiddenLayer  = tf.nn.sigmoid(hiddenLayer)\n",
    "# 输出层\n",
    "outputWeight = tf.Variable(tf.truncated_normal([hiddenSize, outputSize], mean=0, stddev=0.1))\n",
    "outputBias   = tf.Variable(tf.truncated_normal([outputSize], mean=0, stddev=0.1))\n",
    "outputLayer  = tf.add(tf.matmul(hiddenLayer, outputWeight), outputBias)\n",
    "outputLayer  = tf.nn.sigmoid(outputLayer)\n",
    "# 标签\n",
    "outputLabel = tf.placeholder(tf.float32, shape=[None, outputSize])\n",
    "# 损失函数\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=outputLabel, logits=outputLayer))\n",
    "# 优化器\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "# 训练目标\n",
    "target = optimizer.minimize(loss)\n",
    "# 训练\n",
    "\n",
    "accuracy_need=[]\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(trainCycle):\n",
    "        batch = mnist.train.next_batch(batchSize)\n",
    "        sess.run(target, feed_dict={inputLayer: batch[0], outputLabel: batch[1]})\n",
    "        if i%(100)==0 and i!=0:\n",
    "            corrected = tf.equal(tf.argmax(outputLabel, 1), tf.argmax(outputLayer, 1))\n",
    "            accuracy  = tf.reduce_mean(tf.cast(corrected, tf.float32))\n",
    "            accuracyValue = sess.run(accuracy, feed_dict={inputLayer: mnist.test.images, outputLabel: mnist.test.labels})\n",
    "            print(\"第\",i,\"张\",\"accuracy on test set:\", accuracyValue)\n",
    "            accuracy_need.append(accuracyValue)\n",
    "    # 测试\n",
    "    corrected = tf.equal(tf.argmax(outputLabel, 1), tf.argmax(outputLayer, 1))\n",
    "    accuracy  = tf.reduce_mean(tf.cast(corrected, tf.float32))\n",
    "    accuracyValue = sess.run(accuracy, feed_dict={inputLayer: mnist.test.images, outputLabel: mnist.test.labels})\n",
    "    print(\"最终 accuracy on test set:\", accuracyValue)\n",
    "    accuracy_need.append(accuracyValue)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accuracy_need)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 100 张 accuracy on test set: 0.1872\n",
      "第 200 张 accuracy on test set: 0.1009\n",
      "第 300 张 accuracy on test set: 0.3274\n",
      "第 400 张 accuracy on test set: 0.3369\n",
      "第 500 张 accuracy on test set: 0.4646\n",
      "第 600 张 accuracy on test set: 0.5171\n",
      "第 700 张 accuracy on test set: 0.5345\n",
      "第 800 张 accuracy on test set: 0.5496\n",
      "第 900 张 accuracy on test set: 0.6588\n",
      "第 1000 张 accuracy on test set: 0.6646\n",
      "第 1100 张 accuracy on test set: 0.6503\n",
      "第 1200 张 accuracy on test set: 0.6592\n",
      "第 1300 张 accuracy on test set: 0.6868\n",
      "第 1400 张 accuracy on test set: 0.7057\n",
      "第 1500 张 accuracy on test set: 0.6631\n",
      "第 1600 张 accuracy on test set: 0.672\n",
      "第 1700 张 accuracy on test set: 0.7113\n",
      "第 1800 张 accuracy on test set: 0.758\n",
      "第 1900 张 accuracy on test set: 0.7625\n",
      "第 2000 张 accuracy on test set: 0.7684\n",
      "第 2100 张 accuracy on test set: 0.7729\n",
      "第 2200 张 accuracy on test set: 0.7741\n",
      "第 2300 张 accuracy on test set: 0.7582\n",
      "第 2400 张 accuracy on test set: 0.7603\n",
      "第 2500 张 accuracy on test set: 0.7434\n",
      "第 2600 张 accuracy on test set: 0.7551\n",
      "第 2700 张 accuracy on test set: 0.7641\n",
      "第 2800 张 accuracy on test set: 0.7607\n",
      "第 2900 张 accuracy on test set: 0.7575\n",
      "第 3000 张 accuracy on test set: 0.7339\n",
      "第 3100 张 accuracy on test set: 0.7593\n",
      "第 3200 张 accuracy on test set: 0.7841\n",
      "第 3300 张 accuracy on test set: 0.7689\n",
      "第 3400 张 accuracy on test set: 0.7548\n",
      "第 3500 张 accuracy on test set: 0.7423\n",
      "第 3600 张 accuracy on test set: 0.7633\n",
      "第 3700 张 accuracy on test set: 0.8131\n",
      "第 3800 张 accuracy on test set: 0.8173\n",
      "第 3900 张 accuracy on test set: 0.8292\n",
      "第 4000 张 accuracy on test set: 0.8308\n",
      "第 4100 张 accuracy on test set: 0.8456\n",
      "第 4200 张 accuracy on test set: 0.7875\n",
      "第 4300 张 accuracy on test set: 0.7838\n",
      "第 4400 张 accuracy on test set: 0.7976\n",
      "第 4500 张 accuracy on test set: 0.8474\n",
      "第 4600 张 accuracy on test set: 0.8441\n",
      "第 4700 张 accuracy on test set: 0.8183\n",
      "第 4800 张 accuracy on test set: 0.8233\n",
      "第 4900 张 accuracy on test set: 0.8263\n",
      "第 5000 张 accuracy on test set: 0.8153\n",
      "第 5100 张 accuracy on test set: 0.8144\n",
      "第 5200 张 accuracy on test set: 0.833\n",
      "第 5300 张 accuracy on test set: 0.8571\n",
      "第 5400 张 accuracy on test set: 0.8613\n",
      "第 5500 张 accuracy on test set: 0.8502\n",
      "第 5600 张 accuracy on test set: 0.8595\n",
      "第 5700 张 accuracy on test set: 0.855\n",
      "第 5800 张 accuracy on test set: 0.8402\n",
      "第 5900 张 accuracy on test set: 0.8276\n",
      "第 6000 张 accuracy on test set: 0.8241\n",
      "第 6100 张 accuracy on test set: 0.8344\n",
      "第 6200 张 accuracy on test set: 0.8695\n",
      "第 6300 张 accuracy on test set: 0.8327\n",
      "第 6400 张 accuracy on test set: 0.8726\n",
      "第 6500 张 accuracy on test set: 0.8528\n",
      "第 6600 张 accuracy on test set: 0.8142\n",
      "第 6700 张 accuracy on test set: 0.8082\n",
      "第 6800 张 accuracy on test set: 0.8085\n",
      "第 6900 张 accuracy on test set: 0.8322\n",
      "第 7000 张 accuracy on test set: 0.8164\n",
      "第 7100 张 accuracy on test set: 0.8067\n",
      "第 7200 张 accuracy on test set: 0.8205\n",
      "第 7300 张 accuracy on test set: 0.814\n",
      "第 7400 张 accuracy on test set: 0.8555\n",
      "第 7500 张 accuracy on test set: 0.8109\n",
      "第 7600 张 accuracy on test set: 0.8089\n",
      "第 7700 张 accuracy on test set: 0.8077\n",
      "第 7800 张 accuracy on test set: 0.8145\n",
      "第 7900 张 accuracy on test set: 0.8136\n",
      "第 8000 张 accuracy on test set: 0.8134\n",
      "第 8100 张 accuracy on test set: 0.8064\n",
      "第 8200 张 accuracy on test set: 0.8123\n",
      "第 8300 张 accuracy on test set: 0.8158\n",
      "第 8400 张 accuracy on test set: 0.8161\n",
      "第 8500 张 accuracy on test set: 0.807\n",
      "第 8600 张 accuracy on test set: 0.8122\n",
      "第 8700 张 accuracy on test set: 0.8092\n",
      "第 8800 张 accuracy on test set: 0.8582\n",
      "第 8900 张 accuracy on test set: 0.8653\n",
      "第 9000 张 accuracy on test set: 0.8205\n",
      "第 9100 张 accuracy on test set: 0.8208\n",
      "第 9200 张 accuracy on test set: 0.8189\n",
      "第 9300 张 accuracy on test set: 0.821\n",
      "第 9400 张 accuracy on test set: 0.821\n",
      "第 9500 张 accuracy on test set: 0.818\n",
      "第 9600 张 accuracy on test set: 0.8212\n",
      "第 9700 张 accuracy on test set: 0.8188\n",
      "第 9800 张 accuracy on test set: 0.8251\n",
      "第 9900 张 accuracy on test set: 0.8256\n",
      "第 10000 张 accuracy on test set: 0.8305\n",
      "第 10100 张 accuracy on test set: 0.8703\n",
      "第 10200 张 accuracy on test set: 0.8568\n",
      "第 10300 张 accuracy on test set: 0.8793\n",
      "第 10400 张 accuracy on test set: 0.8712\n",
      "第 10500 张 accuracy on test set: 0.872\n",
      "第 10600 张 accuracy on test set: 0.8775\n",
      "第 10700 张 accuracy on test set: 0.8672\n",
      "第 10800 张 accuracy on test set: 0.8419\n",
      "第 10900 张 accuracy on test set: 0.8351\n",
      "第 11000 张 accuracy on test set: 0.8751\n",
      "第 11100 张 accuracy on test set: 0.8784\n",
      "第 11200 张 accuracy on test set: 0.8729\n",
      "第 11300 张 accuracy on test set: 0.8493\n",
      "第 11400 张 accuracy on test set: 0.8286\n",
      "第 11500 张 accuracy on test set: 0.8238\n",
      "第 11600 张 accuracy on test set: 0.8235\n",
      "第 11700 张 accuracy on test set: 0.8158\n",
      "第 11800 张 accuracy on test set: 0.8249\n",
      "第 11900 张 accuracy on test set: 0.8717\n",
      "第 12000 张 accuracy on test set: 0.8278\n",
      "第 12100 张 accuracy on test set: 0.8246\n",
      "第 12200 张 accuracy on test set: 0.8266\n",
      "第 12300 张 accuracy on test set: 0.825\n",
      "第 12400 张 accuracy on test set: 0.8229\n",
      "第 12500 张 accuracy on test set: 0.8268\n",
      "第 12600 张 accuracy on test set: 0.826\n",
      "第 12700 张 accuracy on test set: 0.8232\n",
      "第 12800 张 accuracy on test set: 0.8205\n",
      "第 12900 张 accuracy on test set: 0.8165\n",
      "第 13000 张 accuracy on test set: 0.8244\n",
      "第 13100 张 accuracy on test set: 0.8217\n",
      "第 13200 张 accuracy on test set: 0.825\n",
      "第 13300 张 accuracy on test set: 0.8231\n",
      "第 13400 张 accuracy on test set: 0.8234\n",
      "第 13500 张 accuracy on test set: 0.8251\n",
      "第 13600 张 accuracy on test set: 0.8244\n",
      "第 13700 张 accuracy on test set: 0.8287\n",
      "第 13800 张 accuracy on test set: 0.8259\n",
      "第 13900 张 accuracy on test set: 0.8278\n",
      "第 14000 张 accuracy on test set: 0.8296\n",
      "第 14100 张 accuracy on test set: 0.8252\n",
      "第 14200 张 accuracy on test set: 0.824\n",
      "第 14300 张 accuracy on test set: 0.8257\n",
      "第 14400 张 accuracy on test set: 0.8213\n",
      "第 14500 张 accuracy on test set: 0.8253\n",
      "第 14600 张 accuracy on test set: 0.8249\n",
      "第 14700 张 accuracy on test set: 0.8231\n",
      "第 14800 张 accuracy on test set: 0.8249\n",
      "第 14900 张 accuracy on test set: 0.8221\n",
      "第 15000 张 accuracy on test set: 0.8208\n",
      "第 15100 张 accuracy on test set: 0.8268\n",
      "第 15200 张 accuracy on test set: 0.8251\n",
      "第 15300 张 accuracy on test set: 0.8182\n",
      "第 15400 张 accuracy on test set: 0.8293\n",
      "第 15500 张 accuracy on test set: 0.8255\n",
      "第 15600 张 accuracy on test set: 0.823\n",
      "第 15700 张 accuracy on test set: 0.8297\n",
      "第 15800 张 accuracy on test set: 0.8275\n",
      "第 15900 张 accuracy on test set: 0.8218\n",
      "第 16000 张 accuracy on test set: 0.8238\n",
      "第 16100 张 accuracy on test set: 0.8287\n",
      "第 16200 张 accuracy on test set: 0.8301\n",
      "第 16300 张 accuracy on test set: 0.829\n",
      "第 16400 张 accuracy on test set: 0.8284\n",
      "第 16500 张 accuracy on test set: 0.8307\n",
      "第 16600 张 accuracy on test set: 0.8286\n",
      "第 16700 张 accuracy on test set: 0.8296\n",
      "第 16800 张 accuracy on test set: 0.8314\n",
      "第 16900 张 accuracy on test set: 0.8261\n",
      "第 17000 张 accuracy on test set: 0.8245\n",
      "第 17100 张 accuracy on test set: 0.8275\n",
      "第 17200 张 accuracy on test set: 0.8265\n",
      "第 17300 张 accuracy on test set: 0.8291\n",
      "第 17400 张 accuracy on test set: 0.8305\n",
      "第 17500 张 accuracy on test set: 0.8312\n",
      "第 17600 张 accuracy on test set: 0.8311\n",
      "第 17700 张 accuracy on test set: 0.8314\n",
      "第 17800 张 accuracy on test set: 0.8272\n",
      "第 17900 张 accuracy on test set: 0.8282\n",
      "第 18000 张 accuracy on test set: 0.833\n",
      "第 18100 张 accuracy on test set: 0.8299\n",
      "第 18200 张 accuracy on test set: 0.8308\n",
      "第 18300 张 accuracy on test set: 0.8347\n",
      "第 18400 张 accuracy on test set: 0.8281\n",
      "第 18500 张 accuracy on test set: 0.8307\n",
      "第 18600 张 accuracy on test set: 0.8269\n",
      "第 18700 张 accuracy on test set: 0.8289\n",
      "第 18800 张 accuracy on test set: 0.8282\n",
      "第 18900 张 accuracy on test set: 0.8284\n",
      "第 19000 张 accuracy on test set: 0.834\n",
      "第 19100 张 accuracy on test set: 0.83\n",
      "第 19200 张 accuracy on test set: 0.8306\n",
      "第 19300 张 accuracy on test set: 0.8358\n",
      "第 19400 张 accuracy on test set: 0.8296\n",
      "第 19500 张 accuracy on test set: 0.8351\n",
      "第 19600 张 accuracy on test set: 0.8362\n",
      "第 19700 张 accuracy on test set: 0.8349\n",
      "第 19800 张 accuracy on test set: 0.8374\n",
      "第 19900 张 accuracy on test set: 0.8367\n",
      "第 20000 张 accuracy on test set: 0.8356\n",
      "第 20100 张 accuracy on test set: 0.8339\n",
      "第 20200 张 accuracy on test set: 0.8315\n",
      "第 20300 张 accuracy on test set: 0.8377\n",
      "第 20400 张 accuracy on test set: 0.8347\n",
      "第 20500 张 accuracy on test set: 0.8278\n",
      "第 20600 张 accuracy on test set: 0.8361\n",
      "第 20700 张 accuracy on test set: 0.8374\n",
      "第 20800 张 accuracy on test set: 0.8264\n",
      "第 20900 张 accuracy on test set: 0.8344\n",
      "第 21000 张 accuracy on test set: 0.8288\n",
      "第 21100 张 accuracy on test set: 0.8359\n",
      "第 21200 张 accuracy on test set: 0.8342\n",
      "第 21300 张 accuracy on test set: 0.8336\n",
      "第 21400 张 accuracy on test set: 0.8389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 21500 张 accuracy on test set: 0.8405\n",
      "第 21600 张 accuracy on test set: 0.8214\n",
      "第 21700 张 accuracy on test set: 0.8297\n",
      "第 21800 张 accuracy on test set: 0.8389\n",
      "第 21900 张 accuracy on test set: 0.8386\n",
      "第 22000 张 accuracy on test set: 0.839\n",
      "第 22100 张 accuracy on test set: 0.8386\n",
      "第 22200 张 accuracy on test set: 0.8392\n",
      "第 22300 张 accuracy on test set: 0.8372\n",
      "第 22400 张 accuracy on test set: 0.8381\n",
      "第 22500 张 accuracy on test set: 0.835\n",
      "第 22600 张 accuracy on test set: 0.8402\n",
      "第 22700 张 accuracy on test set: 0.8398\n",
      "第 22800 张 accuracy on test set: 0.8347\n",
      "第 22900 张 accuracy on test set: 0.837\n",
      "第 23000 张 accuracy on test set: 0.839\n",
      "第 23100 张 accuracy on test set: 0.8371\n",
      "第 23200 张 accuracy on test set: 0.8366\n",
      "第 23300 张 accuracy on test set: 0.8357\n",
      "第 23400 张 accuracy on test set: 0.833\n",
      "第 23500 张 accuracy on test set: 0.8402\n",
      "第 23600 张 accuracy on test set: 0.838\n",
      "第 23700 张 accuracy on test set: 0.8349\n",
      "第 23800 张 accuracy on test set: 0.8403\n",
      "第 23900 张 accuracy on test set: 0.8341\n",
      "第 24000 张 accuracy on test set: 0.8399\n",
      "第 24100 张 accuracy on test set: 0.8402\n",
      "第 24200 张 accuracy on test set: 0.8424\n",
      "第 24300 张 accuracy on test set: 0.8427\n",
      "第 24400 张 accuracy on test set: 0.8388\n",
      "第 24500 张 accuracy on test set: 0.8416\n",
      "第 24600 张 accuracy on test set: 0.8412\n",
      "第 24700 张 accuracy on test set: 0.8369\n",
      "第 24800 张 accuracy on test set: 0.84\n",
      "第 24900 张 accuracy on test set: 0.8403\n",
      "第 25000 张 accuracy on test set: 0.8391\n",
      "第 25100 张 accuracy on test set: 0.8433\n",
      "第 25200 张 accuracy on test set: 0.8408\n",
      "第 25300 张 accuracy on test set: 0.8349\n",
      "第 25400 张 accuracy on test set: 0.8321\n",
      "第 25500 张 accuracy on test set: 0.8385\n",
      "第 25600 张 accuracy on test set: 0.8414\n",
      "第 25700 张 accuracy on test set: 0.8422\n",
      "第 25800 张 accuracy on test set: 0.8417\n",
      "第 25900 张 accuracy on test set: 0.838\n",
      "第 26000 张 accuracy on test set: 0.8374\n",
      "第 26100 张 accuracy on test set: 0.8375\n",
      "第 26200 张 accuracy on test set: 0.836\n",
      "第 26300 张 accuracy on test set: 0.8431\n",
      "第 26400 张 accuracy on test set: 0.8466\n",
      "第 26500 张 accuracy on test set: 0.8451\n",
      "第 26600 张 accuracy on test set: 0.8405\n",
      "第 26700 张 accuracy on test set: 0.8396\n",
      "第 26800 张 accuracy on test set: 0.8401\n",
      "第 26900 张 accuracy on test set: 0.8408\n",
      "第 27000 张 accuracy on test set: 0.8416\n",
      "第 27100 张 accuracy on test set: 0.8421\n",
      "第 27200 张 accuracy on test set: 0.8428\n",
      "第 27300 张 accuracy on test set: 0.8433\n",
      "第 27400 张 accuracy on test set: 0.8263\n",
      "第 27500 张 accuracy on test set: 0.8394\n",
      "第 27600 张 accuracy on test set: 0.8451\n",
      "第 27700 张 accuracy on test set: 0.8441\n",
      "第 27800 张 accuracy on test set: 0.841\n",
      "第 27900 张 accuracy on test set: 0.8407\n",
      "第 28000 张 accuracy on test set: 0.8462\n",
      "第 28100 张 accuracy on test set: 0.8413\n",
      "第 28200 张 accuracy on test set: 0.8441\n",
      "第 28300 张 accuracy on test set: 0.8444\n",
      "第 28400 张 accuracy on test set: 0.8416\n",
      "第 28500 张 accuracy on test set: 0.8439\n",
      "第 28600 张 accuracy on test set: 0.8444\n",
      "第 28700 张 accuracy on test set: 0.843\n",
      "第 28800 张 accuracy on test set: 0.8437\n",
      "第 28900 张 accuracy on test set: 0.8465\n",
      "第 29000 张 accuracy on test set: 0.844\n",
      "第 29100 张 accuracy on test set: 0.8434\n",
      "第 29200 张 accuracy on test set: 0.842\n",
      "第 29300 张 accuracy on test set: 0.8431\n",
      "第 29400 张 accuracy on test set: 0.8467\n",
      "第 29500 张 accuracy on test set: 0.8502\n",
      "第 29600 张 accuracy on test set: 0.8488\n",
      "第 29700 张 accuracy on test set: 0.8479\n",
      "第 29800 张 accuracy on test set: 0.8445\n",
      "第 29900 张 accuracy on test set: 0.8421\n",
      "第 30000 张 accuracy on test set: 0.8458\n",
      "第 30100 张 accuracy on test set: 0.8413\n",
      "第 30200 张 accuracy on test set: 0.8473\n",
      "第 30300 张 accuracy on test set: 0.8496\n",
      "第 30400 张 accuracy on test set: 0.8509\n",
      "第 30500 张 accuracy on test set: 0.8488\n",
      "第 30600 张 accuracy on test set: 0.8471\n",
      "第 30700 张 accuracy on test set: 0.8462\n",
      "第 30800 张 accuracy on test set: 0.8421\n",
      "第 30900 张 accuracy on test set: 0.8473\n",
      "第 31000 张 accuracy on test set: 0.8464\n",
      "第 31100 张 accuracy on test set: 0.8398\n",
      "第 31200 张 accuracy on test set: 0.8475\n",
      "第 31300 张 accuracy on test set: 0.8432\n",
      "第 31400 张 accuracy on test set: 0.8462\n",
      "第 31500 张 accuracy on test set: 0.8442\n",
      "第 31600 张 accuracy on test set: 0.8418\n",
      "第 31700 张 accuracy on test set: 0.8429\n",
      "第 31800 张 accuracy on test set: 0.8465\n",
      "第 31900 张 accuracy on test set: 0.8463\n",
      "第 32000 张 accuracy on test set: 0.8446\n",
      "第 32100 张 accuracy on test set: 0.8454\n",
      "第 32200 张 accuracy on test set: 0.8462\n",
      "第 32300 张 accuracy on test set: 0.8471\n",
      "第 32400 张 accuracy on test set: 0.8462\n",
      "第 32500 张 accuracy on test set: 0.844\n",
      "第 32600 张 accuracy on test set: 0.8464\n",
      "第 32700 张 accuracy on test set: 0.8464\n",
      "第 32800 张 accuracy on test set: 0.8457\n",
      "第 32900 张 accuracy on test set: 0.8441\n",
      "第 33000 张 accuracy on test set: 0.8424\n",
      "第 33100 张 accuracy on test set: 0.8434\n",
      "第 33200 张 accuracy on test set: 0.8395\n",
      "第 33300 张 accuracy on test set: 0.8436\n",
      "第 33400 张 accuracy on test set: 0.8356\n",
      "第 33500 张 accuracy on test set: 0.8399\n",
      "第 33600 张 accuracy on test set: 0.842\n",
      "第 33700 张 accuracy on test set: 0.8464\n",
      "第 33800 张 accuracy on test set: 0.8489\n",
      "第 33900 张 accuracy on test set: 0.8504\n",
      "第 34000 张 accuracy on test set: 0.8498\n",
      "第 34100 张 accuracy on test set: 0.8475\n",
      "第 34200 张 accuracy on test set: 0.8549\n",
      "第 34300 张 accuracy on test set: 0.8531\n",
      "第 34400 张 accuracy on test set: 0.8506\n",
      "第 34500 张 accuracy on test set: 0.851\n",
      "第 34600 张 accuracy on test set: 0.8572\n",
      "第 34700 张 accuracy on test set: 0.8585\n",
      "第 34800 张 accuracy on test set: 0.8609\n",
      "第 34900 张 accuracy on test set: 0.8913\n",
      "第 35000 张 accuracy on test set: 0.8607\n",
      "第 35100 张 accuracy on test set: 0.8532\n",
      "第 35200 张 accuracy on test set: 0.8497\n",
      "第 35300 张 accuracy on test set: 0.8579\n",
      "第 35400 张 accuracy on test set: 0.8526\n",
      "第 35500 张 accuracy on test set: 0.8658\n",
      "第 35600 张 accuracy on test set: 0.8684\n",
      "第 35700 张 accuracy on test set: 0.8686\n",
      "第 35800 张 accuracy on test set: 0.859\n",
      "第 35900 张 accuracy on test set: 0.8509\n",
      "第 36000 张 accuracy on test set: 0.8517\n",
      "第 36100 张 accuracy on test set: 0.8658\n",
      "第 36200 张 accuracy on test set: 0.857\n",
      "第 36300 张 accuracy on test set: 0.8597\n",
      "第 36400 张 accuracy on test set: 0.8617\n",
      "第 36500 张 accuracy on test set: 0.8581\n",
      "第 36600 张 accuracy on test set: 0.8562\n",
      "第 36700 张 accuracy on test set: 0.8587\n",
      "第 36800 张 accuracy on test set: 0.8558\n",
      "第 36900 张 accuracy on test set: 0.8543\n",
      "第 37000 张 accuracy on test set: 0.8572\n",
      "第 37100 张 accuracy on test set: 0.8596\n",
      "第 37200 张 accuracy on test set: 0.8573\n",
      "第 37300 张 accuracy on test set: 0.8633\n",
      "第 37400 张 accuracy on test set: 0.8604\n",
      "第 37500 张 accuracy on test set: 0.8534\n",
      "第 37600 张 accuracy on test set: 0.8511\n",
      "第 37700 张 accuracy on test set: 0.8505\n",
      "第 37800 张 accuracy on test set: 0.8545\n",
      "第 37900 张 accuracy on test set: 0.8528\n",
      "第 38000 张 accuracy on test set: 0.8536\n",
      "第 38100 张 accuracy on test set: 0.8555\n",
      "第 38200 张 accuracy on test set: 0.8534\n",
      "第 38300 张 accuracy on test set: 0.8541\n",
      "第 38400 张 accuracy on test set: 0.8578\n",
      "第 38500 张 accuracy on test set: 0.8587\n",
      "第 38600 张 accuracy on test set: 0.8476\n",
      "第 38700 张 accuracy on test set: 0.8546\n",
      "第 38800 张 accuracy on test set: 0.8553\n",
      "第 38900 张 accuracy on test set: 0.8599\n",
      "第 39000 张 accuracy on test set: 0.8548\n",
      "第 39100 张 accuracy on test set: 0.8539\n",
      "第 39200 张 accuracy on test set: 0.8553\n",
      "第 39300 张 accuracy on test set: 0.8558\n",
      "第 39400 张 accuracy on test set: 0.8506\n",
      "第 39500 张 accuracy on test set: 0.8518\n",
      "第 39600 张 accuracy on test set: 0.8566\n",
      "第 39700 张 accuracy on test set: 0.8454\n",
      "第 39800 张 accuracy on test set: 0.8482\n",
      "第 39900 张 accuracy on test set: 0.8512\n",
      "第 40000 张 accuracy on test set: 0.8463\n",
      "第 40100 张 accuracy on test set: 0.8493\n",
      "第 40200 张 accuracy on test set: 0.852\n",
      "第 40300 张 accuracy on test set: 0.8553\n",
      "第 40400 张 accuracy on test set: 0.8615\n",
      "第 40500 张 accuracy on test set: 0.8475\n",
      "第 40600 张 accuracy on test set: 0.8509\n",
      "第 40700 张 accuracy on test set: 0.8513\n",
      "第 40800 张 accuracy on test set: 0.8556\n",
      "第 40900 张 accuracy on test set: 0.855\n",
      "第 41000 张 accuracy on test set: 0.859\n",
      "第 41100 张 accuracy on test set: 0.8551\n",
      "第 41200 张 accuracy on test set: 0.8589\n",
      "第 41300 张 accuracy on test set: 0.8577\n",
      "第 41400 张 accuracy on test set: 0.8534\n",
      "第 41500 张 accuracy on test set: 0.8475\n",
      "第 41600 张 accuracy on test set: 0.8557\n",
      "第 41700 张 accuracy on test set: 0.8535\n",
      "第 41800 张 accuracy on test set: 0.8518\n",
      "第 41900 张 accuracy on test set: 0.8482\n",
      "第 42000 张 accuracy on test set: 0.8504\n",
      "第 42100 张 accuracy on test set: 0.8568\n",
      "第 42200 张 accuracy on test set: 0.8572\n",
      "第 42300 张 accuracy on test set: 0.8556\n",
      "第 42400 张 accuracy on test set: 0.8641\n",
      "第 42500 张 accuracy on test set: 0.8584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 42600 张 accuracy on test set: 0.8506\n",
      "第 42700 张 accuracy on test set: 0.8509\n",
      "第 42800 张 accuracy on test set: 0.8579\n",
      "第 42900 张 accuracy on test set: 0.8546\n",
      "第 43000 张 accuracy on test set: 0.8543\n",
      "第 43100 张 accuracy on test set: 0.8598\n",
      "第 43200 张 accuracy on test set: 0.8585\n",
      "第 43300 张 accuracy on test set: 0.8629\n",
      "第 43400 张 accuracy on test set: 0.8642\n",
      "第 43500 张 accuracy on test set: 0.8578\n",
      "第 43600 张 accuracy on test set: 0.85\n",
      "第 43700 张 accuracy on test set: 0.8506\n",
      "第 43800 张 accuracy on test set: 0.8531\n",
      "第 43900 张 accuracy on test set: 0.8572\n",
      "第 44000 张 accuracy on test set: 0.8561\n",
      "第 44100 张 accuracy on test set: 0.873\n",
      "第 44200 张 accuracy on test set: 0.8785\n",
      "第 44300 张 accuracy on test set: 0.8834\n",
      "第 44400 张 accuracy on test set: 0.9103\n",
      "第 44500 张 accuracy on test set: 0.9228\n",
      "第 44600 张 accuracy on test set: 0.8941\n",
      "第 44700 张 accuracy on test set: 0.9024\n",
      "第 44800 张 accuracy on test set: 0.9102\n",
      "第 44900 张 accuracy on test set: 0.9215\n",
      "第 45000 张 accuracy on test set: 0.8933\n",
      "第 45100 张 accuracy on test set: 0.901\n",
      "第 45200 张 accuracy on test set: 0.8784\n",
      "第 45300 张 accuracy on test set: 0.9111\n",
      "第 45400 张 accuracy on test set: 0.9028\n",
      "第 45500 张 accuracy on test set: 0.9122\n",
      "第 45600 张 accuracy on test set: 0.8975\n",
      "第 45700 张 accuracy on test set: 0.8825\n",
      "第 45800 张 accuracy on test set: 0.8836\n",
      "第 45900 张 accuracy on test set: 0.887\n",
      "第 46000 张 accuracy on test set: 0.8719\n",
      "第 46100 张 accuracy on test set: 0.866\n",
      "第 46200 张 accuracy on test set: 0.8658\n",
      "第 46300 张 accuracy on test set: 0.8602\n",
      "第 46400 张 accuracy on test set: 0.8721\n",
      "第 46500 张 accuracy on test set: 0.8973\n",
      "第 46600 张 accuracy on test set: 0.8878\n",
      "第 46700 张 accuracy on test set: 0.8777\n",
      "第 46800 张 accuracy on test set: 0.884\n",
      "第 46900 张 accuracy on test set: 0.9038\n",
      "第 47000 张 accuracy on test set: 0.8877\n",
      "第 47100 张 accuracy on test set: 0.912\n",
      "第 47200 张 accuracy on test set: 0.8812\n",
      "第 47300 张 accuracy on test set: 0.8798\n",
      "第 47400 张 accuracy on test set: 0.8781\n",
      "第 47500 张 accuracy on test set: 0.8682\n",
      "第 47600 张 accuracy on test set: 0.8993\n",
      "第 47700 张 accuracy on test set: 0.8982\n",
      "第 47800 张 accuracy on test set: 0.8796\n",
      "第 47900 张 accuracy on test set: 0.9084\n",
      "第 48000 张 accuracy on test set: 0.894\n",
      "第 48100 张 accuracy on test set: 0.8938\n",
      "第 48200 张 accuracy on test set: 0.888\n",
      "第 48300 张 accuracy on test set: 0.8996\n",
      "第 48400 张 accuracy on test set: 0.8873\n",
      "第 48500 张 accuracy on test set: 0.8943\n",
      "第 48600 张 accuracy on test set: 0.8486\n",
      "第 48700 张 accuracy on test set: 0.8536\n",
      "第 48800 张 accuracy on test set: 0.8573\n",
      "第 48900 张 accuracy on test set: 0.8593\n",
      "第 49000 张 accuracy on test set: 0.8585\n",
      "第 49100 张 accuracy on test set: 0.8695\n",
      "第 49200 张 accuracy on test set: 0.8721\n",
      "第 49300 张 accuracy on test set: 0.8807\n",
      "第 49400 张 accuracy on test set: 0.8909\n",
      "第 49500 张 accuracy on test set: 0.8829\n",
      "第 49600 张 accuracy on test set: 0.8676\n",
      "第 49700 张 accuracy on test set: 0.8738\n",
      "第 49800 张 accuracy on test set: 0.8642\n",
      "第 49900 张 accuracy on test set: 0.8612\n",
      "第 50000 张 accuracy on test set: 0.8648\n",
      "第 50100 张 accuracy on test set: 0.8658\n",
      "第 50200 张 accuracy on test set: 0.8776\n",
      "第 50300 张 accuracy on test set: 0.8958\n",
      "第 50400 张 accuracy on test set: 0.8718\n",
      "第 50500 张 accuracy on test set: 0.8612\n",
      "第 50600 张 accuracy on test set: 0.8655\n",
      "第 50700 张 accuracy on test set: 0.8531\n",
      "第 50800 张 accuracy on test set: 0.8577\n",
      "第 50900 张 accuracy on test set: 0.8561\n",
      "第 51000 张 accuracy on test set: 0.8982\n",
      "第 51100 张 accuracy on test set: 0.9029\n",
      "第 51200 张 accuracy on test set: 0.9103\n",
      "第 51300 张 accuracy on test set: 0.8947\n",
      "第 51400 张 accuracy on test set: 0.9175\n",
      "第 51500 张 accuracy on test set: 0.9074\n",
      "第 51600 张 accuracy on test set: 0.8962\n",
      "第 51700 张 accuracy on test set: 0.8794\n",
      "第 51800 张 accuracy on test set: 0.8797\n",
      "第 51900 张 accuracy on test set: 0.883\n",
      "第 52000 张 accuracy on test set: 0.8625\n",
      "第 52100 张 accuracy on test set: 0.8704\n",
      "第 52200 张 accuracy on test set: 0.8586\n",
      "第 52300 张 accuracy on test set: 0.8867\n",
      "第 52400 张 accuracy on test set: 0.8732\n",
      "第 52500 张 accuracy on test set: 0.8859\n",
      "第 52600 张 accuracy on test set: 0.8963\n",
      "第 52700 张 accuracy on test set: 0.8937\n",
      "第 52800 张 accuracy on test set: 0.9097\n",
      "第 52900 张 accuracy on test set: 0.9259\n",
      "第 53000 张 accuracy on test set: 0.9251\n",
      "第 53100 张 accuracy on test set: 0.9268\n",
      "第 53200 张 accuracy on test set: 0.9317\n",
      "第 53300 张 accuracy on test set: 0.9288\n",
      "第 53400 张 accuracy on test set: 0.9167\n",
      "第 53500 张 accuracy on test set: 0.9175\n",
      "第 53600 张 accuracy on test set: 0.8938\n",
      "第 53700 张 accuracy on test set: 0.8986\n",
      "第 53800 张 accuracy on test set: 0.8986\n",
      "第 53900 张 accuracy on test set: 0.9042\n",
      "第 54000 张 accuracy on test set: 0.8974\n",
      "第 54100 张 accuracy on test set: 0.8951\n",
      "第 54200 张 accuracy on test set: 0.926\n",
      "第 54300 张 accuracy on test set: 0.9301\n",
      "第 54400 张 accuracy on test set: 0.9215\n",
      "第 54500 张 accuracy on test set: 0.9265\n",
      "第 54600 张 accuracy on test set: 0.9248\n",
      "第 54700 张 accuracy on test set: 0.9011\n",
      "第 54800 张 accuracy on test set: 0.8943\n",
      "第 54900 张 accuracy on test set: 0.9261\n",
      "第 55000 张 accuracy on test set: 0.9349\n",
      "第 55100 张 accuracy on test set: 0.9354\n",
      "第 55200 张 accuracy on test set: 0.9342\n",
      "第 55300 张 accuracy on test set: 0.9321\n",
      "第 55400 张 accuracy on test set: 0.8941\n",
      "第 55500 张 accuracy on test set: 0.8833\n",
      "第 55600 张 accuracy on test set: 0.9164\n",
      "第 55700 张 accuracy on test set: 0.8953\n",
      "第 55800 张 accuracy on test set: 0.9056\n",
      "第 55900 张 accuracy on test set: 0.8936\n",
      "第 56000 张 accuracy on test set: 0.9055\n",
      "第 56100 张 accuracy on test set: 0.9088\n",
      "第 56200 张 accuracy on test set: 0.9034\n",
      "第 56300 张 accuracy on test set: 0.9139\n",
      "第 56400 张 accuracy on test set: 0.9022\n",
      "第 56500 张 accuracy on test set: 0.9085\n",
      "第 56600 张 accuracy on test set: 0.9102\n",
      "第 56700 张 accuracy on test set: 0.9009\n",
      "第 56800 张 accuracy on test set: 0.9061\n",
      "第 56900 张 accuracy on test set: 0.8969\n",
      "第 57000 张 accuracy on test set: 0.9097\n",
      "第 57100 张 accuracy on test set: 0.9437\n",
      "第 57200 张 accuracy on test set: 0.934\n",
      "第 57300 张 accuracy on test set: 0.9394\n",
      "第 57400 张 accuracy on test set: 0.9419\n",
      "第 57500 张 accuracy on test set: 0.9395\n",
      "第 57600 张 accuracy on test set: 0.9395\n",
      "第 57700 张 accuracy on test set: 0.9356\n",
      "第 57800 张 accuracy on test set: 0.9397\n",
      "第 57900 张 accuracy on test set: 0.9341\n",
      "第 58000 张 accuracy on test set: 0.9349\n",
      "第 58100 张 accuracy on test set: 0.9196\n",
      "第 58200 张 accuracy on test set: 0.9206\n",
      "第 58300 张 accuracy on test set: 0.941\n",
      "第 58400 张 accuracy on test set: 0.9325\n",
      "第 58500 张 accuracy on test set: 0.9285\n",
      "第 58600 张 accuracy on test set: 0.9258\n",
      "第 58700 张 accuracy on test set: 0.9219\n",
      "第 58800 张 accuracy on test set: 0.9214\n",
      "第 58900 张 accuracy on test set: 0.9187\n",
      "第 59000 张 accuracy on test set: 0.9005\n",
      "第 59100 张 accuracy on test set: 0.9159\n",
      "第 59200 张 accuracy on test set: 0.9074\n",
      "第 59300 张 accuracy on test set: 0.9012\n",
      "第 59400 张 accuracy on test set: 0.9303\n",
      "第 59500 张 accuracy on test set: 0.9188\n",
      "第 59600 张 accuracy on test set: 0.9123\n",
      "第 59700 张 accuracy on test set: 0.9331\n",
      "第 59800 张 accuracy on test set: 0.9356\n",
      "第 59900 张 accuracy on test set: 0.9276\n",
      "最终 accuracy on test set: 0.9234\n"
     ]
    }
   ],
   "source": [
    "inputSize  = 784\n",
    "outputSize = 10\n",
    "hiddenSize = 89\n",
    "hiddenSize2 = 40\n",
    "batchSize  = 1\n",
    "trainCycle = 60000\n",
    "# 输入层\n",
    "inputLayer = tf.placeholder(tf.float32, shape=[None, inputSize])\n",
    "# 隐藏层\n",
    "hiddenWeight = tf.Variable(tf.truncated_normal([inputSize, hiddenSize], mean=0, stddev=0.1))\n",
    "hiddenBias   = tf.Variable(tf.truncated_normal([hiddenSize]))\n",
    "hiddenLayer  = tf.add(tf.matmul(inputLayer, hiddenWeight), hiddenBias)\n",
    "hiddenLayer  = tf.nn.sigmoid(hiddenLayer)\n",
    "\n",
    "# 隐藏层\n",
    "hiddenWeight2 = tf.Variable(tf.truncated_normal([hiddenSize, hiddenSize2], mean=0, stddev=0.1))\n",
    "hiddenBias2   = tf.Variable(tf.truncated_normal([hiddenSize2]))\n",
    "hiddenLayer2  = tf.add(tf.matmul(hiddenLayer, hiddenWeight2), hiddenBias2)\n",
    "hiddenLayer2  = tf.nn.sigmoid(hiddenLayer2)\n",
    "\n",
    "# 输出层\n",
    "outputWeight = tf.Variable(tf.truncated_normal([hiddenSize2, outputSize], mean=0, stddev=0.1))\n",
    "outputBias   = tf.Variable(tf.truncated_normal([outputSize], mean=0, stddev=0.1))\n",
    "outputLayer  = tf.add(tf.matmul(hiddenLayer2, outputWeight), outputBias)\n",
    "outputLayer  = tf.nn.sigmoid(outputLayer)\n",
    "# 标签\n",
    "outputLabel = tf.placeholder(tf.float32, shape=[None, outputSize])\n",
    "# 损失函数\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=outputLabel, logits=outputLayer))\n",
    "# 优化器\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "# 训练目标\n",
    "target = optimizer.minimize(loss)\n",
    "# 训练\n",
    "\n",
    "accuracy_need4=[]\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(trainCycle):\n",
    "        batch = mnist.train.next_batch(batchSize)\n",
    "        sess.run(target, feed_dict={inputLayer: batch[0], outputLabel: batch[1]})\n",
    "        if i%(100)==0 and i!=0:\n",
    "            corrected = tf.equal(tf.argmax(outputLabel, 1), tf.argmax(outputLayer, 1))\n",
    "            accuracy  = tf.reduce_mean(tf.cast(corrected, tf.float32))\n",
    "            accuracyValue = sess.run(accuracy, feed_dict={inputLayer: mnist.test.images, outputLabel: mnist.test.labels})\n",
    "            print(\"第\",i,\"张\",\"accuracy on test set:\", accuracyValue)\n",
    "            accuracy_need4.append(accuracyValue)\n",
    "    # 测试\n",
    "    corrected = tf.equal(tf.argmax(outputLabel, 1), tf.argmax(outputLayer, 1))\n",
    "    accuracy  = tf.reduce_mean(tf.cast(corrected, tf.float32))\n",
    "    accuracyValue = sess.run(accuracy, feed_dict={inputLayer: mnist.test.images, outputLabel: mnist.test.labels})\n",
    "    print(\"最终 accuracy on test set:\", accuracyValue)\n",
    "    accuracy_need4.append(accuracyValue)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accuracy_need4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 作图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy rate')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108a950ac50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pylab import *\n",
    "%matplotlib inline\n",
    "t = np.arange(700,60000, 100)\n",
    "plot(t, accuracy_need2[7:], color=\"blue\", linewidth=2.5, linestyle=\"-\", label=\"2 layer\")\n",
    "plot(t, accuracy_need[7:], color=\"red\",  linewidth=2.5, linestyle=\"-\", label=\"3 layer\")\n",
    "plot(t, accuracy_need4[7:], color=\"green\",  linewidth=2.5, linestyle=\"-\", label=\"4 layer\")\n",
    "legend(loc='lower right')\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('accuracy rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 三层网络时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练60000轮总用时 46.688996714275504 s\n",
      "最终 accuracy on test set: 0.9389\n"
     ]
    }
   ],
   "source": [
    "inputSize  = 784\n",
    "outputSize = 10\n",
    "hiddenSize = 89\n",
    "batchSize  = 1\n",
    "trainCycle = 60000\n",
    "# 输入层\n",
    "inputLayer = tf.placeholder(tf.float32, shape=[None, inputSize])\n",
    "# 隐藏层\n",
    "hiddenWeight = tf.Variable(tf.truncated_normal([inputSize, hiddenSize], mean=0, stddev=0.1))\n",
    "hiddenBias   = tf.Variable(tf.truncated_normal([hiddenSize]))\n",
    "hiddenLayer  = tf.add(tf.matmul(inputLayer, hiddenWeight), hiddenBias)\n",
    "hiddenLayer  = tf.nn.sigmoid(hiddenLayer)\n",
    "# 输出层\n",
    "outputWeight = tf.Variable(tf.truncated_normal([hiddenSize, outputSize], mean=0, stddev=0.1))\n",
    "outputBias   = tf.Variable(tf.truncated_normal([outputSize], mean=0, stddev=0.1))\n",
    "outputLayer  = tf.add(tf.matmul(hiddenLayer, outputWeight), outputBias)\n",
    "outputLayer  = tf.nn.sigmoid(outputLayer)\n",
    "# 标签\n",
    "outputLabel = tf.placeholder(tf.float32, shape=[None, outputSize])\n",
    "# 损失函数\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=outputLabel, logits=outputLayer))\n",
    "# 优化器\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "# 训练目标\n",
    "target = optimizer.minimize(loss)\n",
    "# 训练\n",
    "\n",
    "start =time.clock()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(trainCycle):\n",
    "        batch = mnist.train.next_batch(batchSize)\n",
    "        sess.run(target, feed_dict={inputLayer: batch[0], outputLabel: batch[1]})\n",
    "    end =time.clock()\n",
    "    print(\"训练60000轮总用时\", end-start,\"s\")\n",
    "    # 测试\n",
    "    corrected = tf.equal(tf.argmax(outputLabel, 1), tf.argmax(outputLayer, 1))\n",
    "    accuracy  = tf.reduce_mean(tf.cast(corrected, tf.float32))\n",
    "    accuracyValue = sess.run(accuracy, feed_dict={inputLayer: mnist.test.images, outputLabel: mnist.test.labels})\n",
    "    print(\"最终 accuracy on test set:\", accuracyValue)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  自己实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(0)\n",
    "def tanh(x):\n",
    "    return (np.exp(x)-np.exp(-1*x))/(np.exp(x)+np.exp(-1*x))\n",
    "def dtanh(y):\n",
    "    return 1.0 - y*y\n",
    "\n",
    "class NN:\n",
    "    def __init__(self, ni, nh_li, no):\n",
    "        # 输入层、隐藏层列表、输出层\n",
    "        self.ni = ni \n",
    "        self.nh_li = nh_li\n",
    "        self.nh_len = len(nh_li)\n",
    "        self.no = no\n",
    "        self.w = []#输入层到第一层隐含层，。。。，最后一层隐含层到输出层 总长度为 nh_len+1\n",
    "        \n",
    "        self.w.append(np.random.normal(0.0, pow(self.nh_li[0],-0.5), (self.nh_li[0],self.ni)))\n",
    "        for i in range(self.nh_len-1):\n",
    "            self.w.append(np.random.normal(0.0, pow(self.nh_li[i+1],-0.5), (self.nh_li[i+1],self.nh_li[i])))\n",
    "        self.w.append(np.random.normal(0.0, pow(self.no,-0.5), (self.no,self.nh_li[self.nh_len-1])))\n",
    "        \n",
    "    def oneRound(self, inputs,targets,N):\n",
    "        targets = np.array(targets,ndmin=2).T\n",
    "        # 激活输入层\n",
    "        inputs = np.array(inputs,ndmin=2).T/255\n",
    "        # 隐含层输出\n",
    "\n",
    "        outputs = []# 输入层到第一个隐含层，。。。，最后一个隐含层到输出层  总长度为 nh_len+1\n",
    "        outputs.append(tanh(np.dot(self.w[0],inputs)))\n",
    "        for i in range(self.nh_len-1):\n",
    "            outputs.append(tanh(np.dot(self.w[i+1],outputs[i])))\n",
    "        # 输出层输出\n",
    "        outputs.append(tanh(np.dot(self.w[self.nh_len], outputs[self.nh_len-1])))\n",
    "        \n",
    "        \n",
    "        deltas = []#输出层，最后一个隐含层 。。。 第一个隐含层  总长度为 nh_len+1\n",
    "        #计算输出层的误差\n",
    "        output_deltas = dtanh(outputs[self.nh_len])*(targets - outputs[self.nh_len])\n",
    "        deltas.append(output_deltas)\n",
    "        for i in range(self.nh_len):\n",
    "            deltas.append(dtanh(outputs[self.nh_len-1-i])* np.dot(self.w[self.nh_len-i].T, deltas[i]))\n",
    "\n",
    "            \n",
    "        for i in range(self.nh_len):\n",
    "            self.w[self.nh_len-i] += N*np.dot(deltas[i], np.transpose(outputs[self.nh_len-i-1]))\n",
    "        self.w[0] += N*np.dot(deltas[self.nh_len], np.transpose(inputs))\n",
    "   \n",
    "        return outputs[self.nh_len]\n",
    "  \n",
    "    def test(self, inputs_list,Y):\n",
    "        le = len(Y)\n",
    "        ans = 0\n",
    "        for i in range(le):\n",
    "            inputs = np.array(inputs_list[i],ndmin=2).T/255\n",
    "            outputs = []# 输入层到第一个隐含层，。。。，最后一个隐含层到输出层  总长度为 nh_len+1\n",
    "            outputs.append(tanh(np.dot(self.w[0],inputs)))\n",
    "            for j in range(self.nh_len-1):\n",
    "                outputs.append(tanh(np.dot(self.w[j+1],outputs[j])))\n",
    "            # 输出层输出\n",
    "            outputs.append(tanh(np.dot(self.w[self.nh_len], outputs[self.nh_len-1])))\n",
    "            if np.argmax(outputs[self.nh_len])==Y[i]:\n",
    "                ans+=1\n",
    "        print('准确率',ans/le)\n",
    "        return ans/le    \n",
    "\n",
    "    def weights(self):\n",
    "        return self.w\n",
    "\n",
    "    def train(self, X, Y,iterations=100, N=0.01):\n",
    "        len_total = len(Y)\n",
    "        for i in range(iterations):\n",
    "            for p in range(len_total):              \n",
    "                inputs = X[p]\n",
    "                target = Y[p]\n",
    "                targets = trans(target)\n",
    "                self.oneRound(inputs,targets,N)  \n",
    "            print(\"第\",i,\"轮\")\n",
    "            self.test(X_test,Y_test)\n",
    "            \n",
    "def trans(li):\n",
    "    re_list =[0.0]*10\n",
    "    re_list[li]=1\n",
    "    return re_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 0 轮\n",
      "准确率 0.9132\n",
      "第 1 轮\n",
      "准确率 0.9253\n",
      "第 2 轮\n",
      "准确率 0.9314\n",
      "第 3 轮\n",
      "准确率 0.9348\n",
      "第 4 轮\n",
      "准确率 0.9374\n",
      "第 5 轮\n",
      "准确率 0.9392\n",
      "第 6 轮\n",
      "准确率 0.9412\n",
      "第 7 轮\n",
      "准确率 0.9424\n",
      "第 8 轮\n",
      "准确率 0.9435\n",
      "第 9 轮\n",
      "准确率 0.9448\n",
      "准确率 0.9448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9448"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num=60000\n",
    "n = NN(784, [89], 10)\n",
    "accuracy_rate_2 = n.train(X_train[:num],Y_train[:num],iterations=10)\n",
    "n.test(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(0)\n",
    "def tanh(x):\n",
    "    return (np.exp(x)-np.exp(-1*x))/(np.exp(x)+np.exp(-1*x))\n",
    "def dtanh(y):\n",
    "    return 1.0 - y*y\n",
    "\n",
    "class NN:\n",
    "    def __init__(self, ni, nh_li, no):\n",
    "        # 输入层、隐藏层列表、输出层\n",
    "        self.ni = ni \n",
    "        self.nh_li = nh_li\n",
    "        self.nh_len = len(nh_li)\n",
    "        self.no = no\n",
    "        self.w = []#输入层到第一层隐含层，。。。，最后一层隐含层到输出层 总长度为 nh_len+1\n",
    "        \n",
    "        self.w.append(np.random.normal(0.0, pow(self.nh_li[0],-0.5), (self.nh_li[0],self.ni)))\n",
    "        for i in range(self.nh_len-1):\n",
    "            self.w.append(np.random.normal(0.0, pow(self.nh_li[i+1],-0.5), (self.nh_li[i+1],self.nh_li[i])))\n",
    "        self.w.append(np.random.normal(0.0, pow(self.no,-0.5), (self.no,self.nh_li[self.nh_len-1])))\n",
    "        \n",
    "    def oneRound(self, inputs,targets,N):\n",
    "        targets = np.array(targets,ndmin=2).T\n",
    "        # 激活输入层\n",
    "        inputs = np.array(inputs,ndmin=2).T/255\n",
    "        # 隐含层输出\n",
    "\n",
    "        outputs = []# 输入层到第一个隐含层，。。。，最后一个隐含层到输出层  总长度为 nh_len+1\n",
    "        outputs.append(tanh(np.dot(self.w[0],inputs)))\n",
    "        for i in range(self.nh_len-1):\n",
    "            outputs.append(tanh(np.dot(self.w[i+1],outputs[i])))\n",
    "        # 输出层输出\n",
    "        outputs.append(tanh(np.dot(self.w[self.nh_len], outputs[self.nh_len-1])))\n",
    "        \n",
    "        \n",
    "        deltas = []#输出层，最后一个隐含层 。。。 第一个隐含层  总长度为 nh_len+1\n",
    "        #计算输出层的误差\n",
    "        output_deltas = dtanh(outputs[self.nh_len])*(targets - outputs[self.nh_len])\n",
    "        deltas.append(output_deltas)\n",
    "        for i in range(self.nh_len):\n",
    "            deltas.append(dtanh(outputs[self.nh_len-1-i])* np.dot(self.w[self.nh_len-i].T, deltas[i]))\n",
    "\n",
    "            \n",
    "        for i in range(self.nh_len):\n",
    "            self.w[self.nh_len-i] += N*np.dot(deltas[i], np.transpose(outputs[self.nh_len-i-1]))\n",
    "        self.w[0] += N*np.dot(deltas[self.nh_len], np.transpose(inputs))\n",
    "   \n",
    "        return outputs[self.nh_len]\n",
    "  \n",
    "    def test(self, inputs_list,Y):\n",
    "        le = len(Y)\n",
    "        ans = 0\n",
    "        for i in range(le):\n",
    "            inputs = np.array(inputs_list[i],ndmin=2).T/255\n",
    "            outputs = []# 输入层到第一个隐含层，。。。，最后一个隐含层到输出层  总长度为 nh_len+1\n",
    "            outputs.append(tanh(np.dot(self.w[0],inputs)))\n",
    "            for j in range(self.nh_len-1):\n",
    "                outputs.append(tanh(np.dot(self.w[j+1],outputs[j])))\n",
    "            # 输出层输出\n",
    "            outputs.append(tanh(np.dot(self.w[self.nh_len], outputs[self.nh_len-1])))\n",
    "            if np.argmax(outputs[self.nh_len])==Y[i]:\n",
    "                ans+=1\n",
    "#         print('准确率',ans/le)\n",
    "        return ans/le    \n",
    "\n",
    "    def weights(self):\n",
    "        return self.w\n",
    "\n",
    "    def train(self, X, Y,iterations=100, N=0.01):\n",
    "        need = []\n",
    "        len_total = len(Y)\n",
    "        for i in range(iterations):\n",
    "            for p in range(len_total):              \n",
    "                inputs = X[p]\n",
    "                target = Y[p]\n",
    "                targets = trans(target)\n",
    "                self.oneRound(inputs,targets,N)  \n",
    "                if p%(100)==0 and p!=0:\n",
    "                    need.append(self.test(X_test,Y_test))\n",
    "        return need\n",
    "            \n",
    "def trans(li):\n",
    "    re_list =[0.0]*10\n",
    "    re_list[li]=1\n",
    "    return re_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9052\n"
     ]
    }
   ],
   "source": [
    "num=60000\n",
    "n = NN(784, [89], 10)\n",
    "accuracy_rate = n.train(X_train[:num],Y_train[:num],iterations=1)\n",
    "print(n.test(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_rate = []\n",
    "t_time = []\n",
    "for i in range(10):\n",
    "    start =time.clock()\n",
    "    kNN_classifier_3 = KNeighborsClassifier(n_neighbors=i+1)\n",
    "    kNN_classifier_3.fit(X_train, Y_train)\n",
    "    end1 =time.clock()\n",
    "    t_time.append(end1-start)\n",
    "#     print(\"当k=\",i+1,\"时，训练所用时间\",end1-start,\"s\")\n",
    "    y_predict_3 = kNN_classifier_3.predict(X_test[:1000])\n",
    "    end2 =time.clock()\n",
    "    acc_rate.append(sum(y_predict_3 == Y_test[:1000])/len(Y_test[:1000]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.946"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kNN_classifier_2 = KNeighborsClassifier(n_neighbors=20)\n",
    "kNN_classifier_2.fit(X_train, Y_train)\n",
    "y_predict_2 = kNN_classifier_2.predict(X_test[:1000])\n",
    "sum(y_predict_2 == Y_test[:1000])/len(Y_test[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.948"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kNN_classifier_2 = KNeighborsClassifier(n_neighbors=2)\n",
    "kNN_classifier_2.fit(X_train, Y_train)\n",
    "y_predict_2 = kNN_classifier_2.predict(X_test[:1000])\n",
    "sum(y_predict_2 == Y_test[:1000])/len(Y_test[:1000])#0.9627#10000  0.9705"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 作图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy rate')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108ae88fd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pylab import *\n",
    "%matplotlib inline\n",
    "t = np.arange(1,11, 1)\n",
    "plot(t, acc_rate, color=\"blue\", linewidth=2.5, linestyle=\"-\", label=\"2 layer\")\n",
    "# plot(t, accuracy_need[7:], color=\"red\",  linewidth=2.5, linestyle=\"-\", label=\"3 layer\")\n",
    "# plot(t, accuracy_need4[7:], color=\"green\",  linewidth=2.5, linestyle=\"-\", label=\"4 layer\")\n",
    "legend(loc='lower right')\n",
    "plt.xlabel('Number of K value')\n",
    "plt.ylabel('accuracy rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 综合比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 78.2% (782/1000) (classification)\n",
      "最终 accuracy on test set: 0.702\n",
      "0.754\n"
     ]
    }
   ],
   "source": [
    "n =500\n",
    "\n",
    "\n",
    "prob  = svm_problem(y_train_svm[:n], x_train_svm[:n])\n",
    "param = svm_parameter('-t 1 -c 4 -m 1024')\n",
    "model = svm_train(prob, param)\n",
    "p_label, p_acc, p_val = svm_predict(y_test_svm[:1000], x_test_svm[:1000], model)\n",
    "\n",
    "\n",
    "inputSize  = 784\n",
    "outputSize = 10\n",
    "hiddenSize = 89\n",
    "batchSize  = 1\n",
    "trainCycle = n\n",
    "# 输入层\n",
    "inputLayer = tf.placeholder(tf.float32, shape=[None, inputSize])\n",
    "# 隐藏层\n",
    "hiddenWeight = tf.Variable(tf.truncated_normal([inputSize, hiddenSize], mean=0, stddev=0.1))\n",
    "hiddenBias   = tf.Variable(tf.truncated_normal([hiddenSize]))\n",
    "hiddenLayer  = tf.add(tf.matmul(inputLayer, hiddenWeight), hiddenBias)\n",
    "hiddenLayer  = tf.nn.sigmoid(hiddenLayer)\n",
    "# 输出层\n",
    "outputWeight = tf.Variable(tf.truncated_normal([hiddenSize, outputSize], mean=0, stddev=0.1))\n",
    "outputBias   = tf.Variable(tf.truncated_normal([outputSize], mean=0, stddev=0.1))\n",
    "outputLayer  = tf.add(tf.matmul(hiddenLayer, outputWeight), outputBias)\n",
    "outputLayer  = tf.nn.sigmoid(outputLayer)\n",
    "# 标签\n",
    "outputLabel = tf.placeholder(tf.float32, shape=[None, outputSize])\n",
    "# 损失函数\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=outputLabel, logits=outputLayer))\n",
    "# 优化器\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "# 训练目标\n",
    "target = optimizer.minimize(loss)\n",
    "# 训练\n",
    "\n",
    "accuracy_need=[]\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(trainCycle):\n",
    "        batch = mnist.train.next_batch(batchSize)\n",
    "        sess.run(target, feed_dict={inputLayer: batch[0], outputLabel: batch[1]})\n",
    "    # 测试\n",
    "    corrected = tf.equal(tf.argmax(outputLabel, 1), tf.argmax(outputLayer, 1))\n",
    "    accuracy  = tf.reduce_mean(tf.cast(corrected, tf.float32))\n",
    "    accuracyValue = sess.run(accuracy, feed_dict={inputLayer: mnist.test.images[:1000], outputLabel: mnist.test.labels[:1000]})\n",
    "    print(\"最终 accuracy on test set:\", accuracyValue)\n",
    "    accuracy_need.append(accuracyValue)\n",
    "    sess.close()\n",
    "    \n",
    "    \n",
    "\n",
    "kNN_classifier_2 = KNeighborsClassifier(n_neighbors=4)\n",
    "kNN_classifier_2.fit(X_train[:n], Y_train[:n])\n",
    "y_predict_2 = kNN_classifier_2.predict(X_test[:1000])\n",
    "n =500print(sum(y_predict_2 == Y_test[:1000])/len(Y_test[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终 accuracy on test set: 0.964\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n =20000\n",
    "\n",
    "\n",
    "inputSize  = 784\n",
    "outputSize = 10\n",
    "hiddenSize = 89\n",
    "batchSize  = 1\n",
    "trainCycle = 10*n\n",
    "# 输入层\n",
    "inputLayer = tf.placeholder(tf.float32, shape=[None, inputSize])\n",
    "# 隐藏层\n",
    "hiddenWeight = tf.Variable(tf.truncated_normal([inputSize, hiddenSize], mean=0, stddev=0.1))\n",
    "hiddenBias   = tf.Variable(tf.truncated_normal([hiddenSize]))\n",
    "hiddenLayer  = tf.add(tf.matmul(inputLayer, hiddenWeight), hiddenBias)\n",
    "hiddenLayer  = tf.nn.sigmoid(hiddenLayer)\n",
    "# 输出层\n",
    "outputWeight = tf.Variable(tf.truncated_normal([hiddenSize, outputSize], mean=0, stddev=0.1))\n",
    "outputBias   = tf.Variable(tf.truncated_normal([outputSize], mean=0, stddev=0.1))\n",
    "outputLayer  = tf.add(tf.matmul(hiddenLayer, outputWeight), outputBias)\n",
    "outputLayer  = tf.nn.sigmoid(outputLayer)\n",
    "# 标签\n",
    "outputLabel = tf.placeholder(tf.float32, shape=[None, outputSize])\n",
    "# 损失函数\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=outputLabel, logits=outputLayer))\n",
    "# 优化器\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "# 训练目标\n",
    "target = optimizer.minimize(loss)\n",
    "# 训练\n",
    "\n",
    "accuracy_need=[]\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(trainCycle):\n",
    "        batch = mnist.train.next_batch(batchSize)\n",
    "        sess.run(target, feed_dict={inputLayer: batch[0], outputLabel: batch[1]})\n",
    "    # 测试\n",
    "    corrected = tf.equal(tf.argmax(outputLabel, 1), tf.argmax(outputLayer, 1))\n",
    "    accuracy  = tf.reduce_mean(tf.cast(corrected, tf.float32))\n",
    "    accuracyValue = sess.run(accuracy, feed_dict={inputLayer: mnist.test.images[:1000], outputLabel: mnist.test.labels[:1000]})\n",
    "    print(\"最终 accuracy on test set:\", accuracyValue)\n",
    "    accuracy_need.append(accuracyValue)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
